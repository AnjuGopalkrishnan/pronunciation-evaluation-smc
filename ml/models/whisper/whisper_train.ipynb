{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Install required packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install speechbrain\n",
    "!pip install textgrid transformers librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import the following packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import logging\n",
    "import speechbrain as sb\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "import librosa\n",
    "import csv\n",
    "from google.colab import drive, files\n",
    "from speechbrain.utils.distributed import run_on_main, if_main_process\n",
    "from speechbrain.tokenizers.SentencePiece import SentencePiece\n",
    "from speechbrain.utils.data_utils import undo_padding\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "from pathlib import Path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Mount google drive"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Mount drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define constants\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "#Change directory to folder in drive\n",
    "\n",
    "folder_path = '/content/drive/MyDrive/CS5647_Project'\n",
    "os.chdir(folder_path)\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Working Directory after change:\", current_directory)\n",
    "\n",
    "#import the mpd eval stats as it is in the same directory\n",
    "from mpd_eval_v3 import MpdStats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining the speech brain class"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define training procedure\n",
    "class ASR(sb.Brain):\n",
    "    def compute_forward(self, batch, stage):\n",
    "        \"\"\"Forward computations from the waveform batches to the output probabilities.\"\"\"\n",
    "        batch = batch.to(self.device)\n",
    "        wavs, wav_lens = batch.sig\n",
    "        wavs, wav_lens = wavs.to(self.device), wav_lens.to(self.device)\n",
    "\n",
    "        # Add augmentation if specified\n",
    "        if stage == sb.Stage.TRAIN:\n",
    "            if hasattr(self.hparams, \"augmentation\"):\n",
    "                wavs = self.hparams.augmentation(wavs, wav_lens)\n",
    "\n",
    "        # Forward pass\n",
    "\n",
    "        # Encode with Whisper and then DNN\n",
    "        feats = self.modules.whisper(wavs)\n",
    "        x = self.modules.enc(feats)\n",
    "\n",
    "        # Compute outputs\n",
    "        logits = self.modules.ctc_lin(x)\n",
    "        p_ctc = self.hparams.log_softmax(logits)\n",
    "\n",
    "        return p_ctc, wav_lens\n",
    "\n",
    "    def compute_objectives(self, predictions, batch, stage):\n",
    "        \"Given the network predictions and targets computed the NLL loss.\"\n",
    "\n",
    "        p_ctc, wav_lens = predictions\n",
    "\n",
    "        ids = batch.id\n",
    "        targets, target_lens = batch.phn_encoded_target\n",
    "        if stage != sb.Stage.TRAIN:\n",
    "            canonicals, canonical_lens = batch.phn_encoded_canonical\n",
    "            perceiveds, perceived_lens = batch.phn_encoded_perceived\n",
    "\n",
    "        loss_ctc = self.hparams.ctc_cost(p_ctc, targets, wav_lens, target_lens)\n",
    "        loss = loss_ctc\n",
    "\n",
    "        # Record losses for posterity\n",
    "        if stage != sb.Stage.TRAIN:\n",
    "            # Note: sb.decoders.ctc_greedy_decode will also remove padded tokens\n",
    "            # that is, it return a list of list with different lengths\n",
    "            sequence = sb.decoders.ctc_greedy_decode(\n",
    "                p_ctc, wav_lens, blank_id=self.hparams.blank_index\n",
    "            )\n",
    "            self.ctc_metrics.append(ids, p_ctc, targets, wav_lens, target_lens)\n",
    "\n",
    "            self.per_metrics.append(\n",
    "                ids=ids,\n",
    "                predict=sequence,\n",
    "                target=targets,\n",
    "                predict_len=None,\n",
    "                target_len=target_lens,\n",
    "                ind2lab=self.label_encoder.decode_ndim,\n",
    "            )\n",
    "            self.mpd_metrics.append(\n",
    "                ids=ids,\n",
    "                predict=sequence,\n",
    "                canonical=canonicals,\n",
    "                perceived=perceiveds,\n",
    "                predict_len=None,\n",
    "                canonical_len=canonical_lens,\n",
    "                perceived_len=perceived_lens,\n",
    "                ind2lab=self.label_encoder.decode_ndim,\n",
    "            )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def evaluate_batch(self, batch, stage):\n",
    "        \"\"\"Computations needed for validation/test batches\"\"\"\n",
    "        predictions = self.compute_forward(batch, stage=stage)\n",
    "        loss = self.compute_objectives(predictions, batch, stage=stage)\n",
    "        return loss.detach()\n",
    "\n",
    "\n",
    "    def on_stage_start(self, stage, epoch):\n",
    "        \"\"\"Gets called at the beginning of each epoch\"\"\"\n",
    "        self.ctc_metrics = self.hparams.ctc_stats()\n",
    "\n",
    "        if stage != sb.Stage.TRAIN:\n",
    "            self.per_metrics = self.hparams.per_stats()\n",
    "            self.mpd_metrics = MpdStats()\n",
    "\n",
    "    def on_stage_end(self, stage, stage_loss, epoch):\n",
    "        \"\"\"Gets called at the end of a epoch.\"\"\"\n",
    "        if stage == sb.Stage.TRAIN:\n",
    "            self.train_loss = stage_loss\n",
    "        else:\n",
    "            per = self.per_metrics.summarize(\"error_rate\")\n",
    "            mpd_f1 = self.mpd_metrics.summarize(\"mpd_f1\")\n",
    "\n",
    "        if stage == sb.Stage.VALID:\n",
    "\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                stats_meta={\n",
    "                    \"epoch\": epoch,\n",
    "                    \"lr_adam\": self.adam_optimizer.param_groups[0][\"lr\"],\n",
    "                    \"lr_whisper\": self.whisper_optimizer.param_groups[0][\"lr\"],\n",
    "                },\n",
    "                train_stats={\"loss\": self.train_loss},\n",
    "                valid_stats={\n",
    "                    \"loss\": stage_loss,\n",
    "                    \"ctc_loss\": self.ctc_metrics.summarize(\"average\"),\n",
    "                    \"PER\": per,\n",
    "                    \"mpd_f1\": mpd_f1\n",
    "                },\n",
    "            )\n",
    "            self.checkpointer.save_and_keep_only(\n",
    "                meta={\"PER\": per, \"mpd_f1\": mpd_f1}, min_keys=[\"PER\"], max_keys=[\"mpd_f1\"]\n",
    "            )\n",
    "\n",
    "        if stage == sb.Stage.TEST:\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                stats_meta={\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
    "                test_stats={\"loss\": stage_loss, \"PER\": per, \"mpd_f1\": mpd_f1},\n",
    "            )\n",
    "            with open(self.hparams.wer_file, \"w\") as w:\n",
    "                w.write(\"CTC loss stats:\\n\")\n",
    "                self.ctc_metrics.write_stats(w)\n",
    "                w.write(\"\\nPER stats:\\n\")\n",
    "                self.per_metrics.write_stats(w)\n",
    "                print(\n",
    "                    \"CTC and PER stats written to file\",\n",
    "                    self.hparams.wer_file,\n",
    "                )\n",
    "            with open(self.hparams.mpd_file, \"w\") as m:\n",
    "                m.write(\"MPD results and stats:\\n\")\n",
    "                self.mpd_metrics.write_stats(m)\n",
    "                print(\n",
    "                    \"MPD results and stats written to file\",\n",
    "                    self.hparams.mpd_file,\n",
    "                )\n",
    "\n",
    "    def fit_batch(self, batch):\n",
    "        \"\"\"Fit one batch, override to do multiple updates.\n",
    "\n",
    "        The default implementation depends on a few methods being defined\n",
    "        with a particular behavior:\n",
    "\n",
    "        * ``compute_forward()``\n",
    "        * ``compute_objectives()``\n",
    "\n",
    "        Also depends on having optimizers passed at initialization.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        batch : list of torch.Tensors\n",
    "            Batch of data to use for training. Default implementation assumes\n",
    "            this batch has two elements: inputs and targets.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        detached loss\n",
    "        \"\"\"\n",
    "        # Managing automatic mixed precision\n",
    "        if self.auto_mix_prec:\n",
    "\n",
    "            self.whisper_optimizer.zero_grad()\n",
    "            self.adam_optimizer.zero_grad()\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = self.compute_forward(batch, sb.Stage.TRAIN)\n",
    "                loss = self.compute_objectives(outputs, batch, sb.Stage.TRAIN)\n",
    "\n",
    "            self.scaler.scale(loss).backward()\n",
    "            self.scaler.unscale_(self.whisper_optimizer)\n",
    "            self.scaler.unscale_(self.adam_optimizer)\n",
    "\n",
    "            if self.check_gradients(loss):\n",
    "                self.scaler.step(self.whisper_optimizer)\n",
    "                self.scaler.step(self.adam_optimizer)\n",
    "\n",
    "            self.scaler.update()\n",
    "        else:\n",
    "            outputs = self.compute_forward(batch, sb.Stage.TRAIN)\n",
    "\n",
    "            loss = self.compute_objectives(outputs, batch, sb.Stage.TRAIN)\n",
    "            # normalize the loss by gradient_accumulation step\n",
    "            (loss / self.hparams.gradient_accumulation).backward()\n",
    "\n",
    "            if self.step % self.hparams.gradient_accumulation == 0:\n",
    "                # gradient clipping & early stop if loss is not fini\n",
    "                if self.check_gradients(loss):\n",
    "                    self.whisper_optimizer.step()\n",
    "                    self.adam_optimizer.step()\n",
    "\n",
    "                self.whisper_optimizer.zero_grad()\n",
    "                self.adam_optimizer.zero_grad()\n",
    "\n",
    "        return loss.detach().cpu()\n",
    "\n",
    "    def init_optimizers(self):\n",
    "        \"Initializes the whisper optimizer and model optimizer\"\n",
    "        self.whisper_optimizer = self.hparams.whisper_opt_class(\n",
    "            self.modules.whisper.parameters()\n",
    "        )\n",
    "\n",
    "        self.adam_optimizer = self.hparams.adam_opt_class(\n",
    "            self.hparams.model.parameters()\n",
    "        )\n",
    "\n",
    "        if self.checkpointer is not None:\n",
    "            self.checkpointer.add_recoverable(\n",
    "                \"whisper_opt\", self.whisper_optimizer\n",
    "            )\n",
    "            self.checkpointer.add_recoverable(\"adam_opt\", self.adam_optimizer)\n",
    "\n",
    "    def on_fit_start(self):\n",
    "        \"\"\"Gets called at the beginning of ``fit()``, on multiple processes\n",
    "        if ``distributed_count > 0`` and backend is ddp.\n",
    "\n",
    "        Default implementation compiles the jit modules, initializes\n",
    "        optimizers, and loads the latest checkpoint to resume training.\n",
    "        \"\"\"\n",
    "        # Run this *after* starting all processes since jit modules cannot be\n",
    "        # pickled.\n",
    "        self._compile_jit()\n",
    "\n",
    "        # Wrap modules with parallel backend after jit\n",
    "        self._wrap_distributed()\n",
    "\n",
    "        # Initialize optimizers after parameters are configured\n",
    "        self.init_optimizers()\n",
    "\n",
    "        # Load latest checkpoint to resume training if interrupted\n",
    "        ## NOTE: make sure to use the \"best\" model to continual training\n",
    "        ## so we set the `min_key` argument\n",
    "        if self.checkpointer is not None:\n",
    "            self.checkpointer.recover_if_possible(\n",
    "                device=torch.device(self.device),\n",
    "                min_key=\"PER\"\n",
    "            )\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def dataio_prep(hparams):\n",
    "    \"\"\"This function prepares the datasets to be used in the brain class.\n",
    "    It also defines the data processing pipeline through user-defined functions.\"\"\"\n",
    "    data_folder = hparams[\"data_folder_save\"]\n",
    "\n",
    "    train_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n",
    "        csv_path=hparams[\"train_annotation\"],\n",
    "        replacements={\"data_root\": data_folder},\n",
    "    )\n",
    "\n",
    "    if hparams[\"sorting\"] == \"ascending\":\n",
    "        # we sort training data to speed up training and get better results.\n",
    "        train_data = train_data.filtered_sorted(sort_key=\"duration\")\n",
    "        # when sorting do not shuffle in dataloader ! otherwise is pointless\n",
    "        hparams[\"train_dataloader_opts\"][\"shuffle\"] = False\n",
    "\n",
    "    elif hparams[\"sorting\"] == \"descending\":\n",
    "        train_data = train_data.filtered_sorted(\n",
    "            sort_key=\"duration\", reverse=True\n",
    "        )\n",
    "        # when sorting do not shuffle in dataloader ! otherwise is pointless\n",
    "        hparams[\"train_dataloader_opts\"][\"shuffle\"] = False\n",
    "\n",
    "    elif hparams[\"sorting\"] == \"random\":\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            \"sorting must be random, ascending or descending\"\n",
    "        )\n",
    "\n",
    "    valid_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n",
    "        csv_path=hparams[\"valid_annotation\"],\n",
    "        replacements={\"data_root\": data_folder},\n",
    "    )\n",
    "    valid_data = valid_data.filtered_sorted(sort_key=\"duration\")\n",
    "\n",
    "    # test is separate\n",
    "    test_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n",
    "        csv_path=hparams[\"test_annotation\"],\n",
    "        replacements={\"data_root\": data_folder},\n",
    "    )\n",
    "    test_data = test_data.filtered_sorted(sort_key=\"duration\")\n",
    "\n",
    "    datasets = [train_data, valid_data, test_data]\n",
    "    label_encoder = sb.dataio.encoder.CTCTextEncoder()\n",
    "\n",
    "    # 2. Define audio pipeline:\n",
    "    @sb.utils.data_pipeline.takes(\"wav\")\n",
    "    @sb.utils.data_pipeline.provides(\"sig\")\n",
    "    def audio_pipeline(wav):\n",
    "        sig = hparams[\"whisper\"].feature_extractor(\n",
    "            librosa.core.load(wav, sr=hparams[\"sample_rate\"])[0],\n",
    "            sampling_rate=hparams[\"sample_rate\"],\n",
    "        ).input_values[0]\n",
    "        sig = torch.Tensor(sig)\n",
    "        return sig\n",
    "\n",
    "    sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline)\n",
    "\n",
    "    # 3. Define text pipeline:\n",
    "  # 3. Define text pipeline:\n",
    "    @sb.utils.data_pipeline.takes(\"perceived_train_target\")\n",
    "    @sb.utils.data_pipeline.provides(\n",
    "        \"phn_list_target\",\n",
    "        \"phn_encoded_list_target\",\n",
    "        \"phn_encoded_target\",\n",
    "    )\n",
    "    def text_pipeline_train(phn):\n",
    "        phn_list = phn.strip().split()\n",
    "        yield phn_list\n",
    "        phn_encoded_list = label_encoder.encode_sequence(phn_list)\n",
    "        yield phn_encoded_list\n",
    "        phn_encoded = torch.LongTensor(phn_encoded_list)\n",
    "        yield phn_encoded\n",
    "\n",
    "    @sb.utils.data_pipeline.takes(\"perceived_train_target\", \"canonical_aligned\", \"perceived_aligned\")\n",
    "    @sb.utils.data_pipeline.provides(\n",
    "        \"phn_list_target\",\n",
    "        \"phn_encoded_list_target\",\n",
    "        \"phn_encoded_target\",\n",
    "        \"phn_list_canonical\",\n",
    "        \"phn_encoded_list_canonical\",\n",
    "        \"phn_encoded_canonical\",\n",
    "        \"phn_list_perceived\",\n",
    "        \"phn_encoded_list_perceived\",\n",
    "        \"phn_encoded_perceived\",\n",
    "    )\n",
    "    def text_pipeline_test(target, canonical, perceived):\n",
    "        phn_list_target = target.strip().split()\n",
    "        yield phn_list_target\n",
    "        phn_encoded_list_target = label_encoder.encode_sequence(phn_list_target)\n",
    "        yield phn_encoded_list_target\n",
    "        phn_encoded_target = torch.LongTensor(phn_encoded_list_target)\n",
    "        yield phn_encoded_target\n",
    "        phn_list_canonical = canonical.strip().split()\n",
    "        yield phn_list_canonical\n",
    "        phn_encoded_list_canonical = label_encoder.encode_sequence(phn_list_canonical)\n",
    "        yield phn_encoded_list_canonical\n",
    "        phn_encoded_canonical = torch.LongTensor(phn_encoded_list_canonical)\n",
    "        yield phn_encoded_canonical\n",
    "        phn_list_perceived = perceived.strip().split()\n",
    "        yield phn_list_perceived\n",
    "        phn_encoded_list_perceived = label_encoder.encode_sequence(phn_list_perceived)\n",
    "        yield phn_encoded_list_perceived\n",
    "        phn_encoded_perceived = torch.LongTensor(phn_encoded_list_perceived)\n",
    "        yield phn_encoded_perceived\n",
    "\n",
    "    sb.dataio.dataset.add_dynamic_item([train_data], text_pipeline_train)\n",
    "    sb.dataio.dataset.add_dynamic_item([valid_data, test_data], text_pipeline_test)\n",
    "\n",
    "    # 3. Fit encoder:\n",
    "    # Load or compute the label encoder\n",
    "    lab_enc_file = os.path.join(hparams[\"save_folder\"], \"label_encoder.txt\")\n",
    "    special_labels = {\n",
    "        \"blank_label\": hparams[\"blank_index\"],\n",
    "    }\n",
    "    label_encoder.load_or_create(\n",
    "        path=lab_enc_file,\n",
    "        from_didatasets=[train_data],\n",
    "        output_key=\"phn_list_target\",\n",
    "        special_labels=special_labels,\n",
    "        sequence_input=True,\n",
    "    )\n",
    "\n",
    "    # 4. Set output:\n",
    "    sb.dataio.dataset.set_output_keys(\n",
    "        [train_data],\n",
    "        [\"id\", \"sig\", \"phn_encoded_target\"],\n",
    "    )\n",
    "    sb.dataio.dataset.set_output_keys(\n",
    "        [valid_data, test_data],\n",
    "        [\"id\", \"sig\", \"phn_encoded_target\", \"phn_encoded_canonical\", \"phn_encoded_perceived\"],\n",
    "    )\n",
    "\n",
    "    return train_data, valid_data, test_data, label_encoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare dataloaders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hparams_file = '/content/drive/MyDrive/CS5647_Project/whisper/hparams/train.yaml'\n",
    "\n",
    "# Load hyperparameters file with command-line overrides\n",
    "with open(hparams_file) as fin:\n",
    "    hparams = load_hyperpyyaml(fin)\n",
    "\n",
    "# Create experiment directory\n",
    "sb.create_experiment_directory(\n",
    "    experiment_directory=hparams[\"output_folder\"],\n",
    "    hyperparams_to_save=hparams_file,\n",
    ")\n",
    "\n",
    "# Dataset IO prep: creating Dataset objects and proper encodings for phones\n",
    "train_data, valid_data, test_data, label_encoder = dataio_prep(hparams)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Instantiating the ASR SB trainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Trainer initialization\n",
    "asr_brain = ASR(\n",
    "    modules=hparams[\"modules\"],\n",
    "    hparams=hparams,\n",
    "    checkpointer=hparams[\"checkpointer\"],\n",
    ")\n",
    "\n",
    "asr_brain.label_encoder = label_encoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training the ASR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training\n",
    "asr_brain.fit(\n",
    "    asr_brain.hparams.epoch_counter,\n",
    "    train_data,\n",
    "    valid_data,\n",
    "    train_loader_kwargs=hparams[\"train_dataloader_opts\"],\n",
    "    valid_loader_kwargs=hparams[\"valid_dataloader_opts\"],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "asr_brain.evaluate(\n",
    "    test_data,\n",
    "    min_key=\"PER\",\n",
    "    test_loader_kwargs=hparams[\"test_dataloader_opts\"],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
