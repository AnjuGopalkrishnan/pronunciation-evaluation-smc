{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kWkjs_8PHcBf",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1697673982465,
     "user_tz": -480,
     "elapsed": 8232,
     "user": {
      "displayName": "lalitha ravi",
      "userId": "00357164084518936800"
     }
    },
    "outputId": "0fc590ba-951d-404c-fd68-8f080e73d301"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting speechbrain\n",
      "  Downloading speechbrain-0.5.15-py3-none-any.whl (553 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m553.8/553.8 kB\u001B[0m \u001B[31m9.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting hyperpyyaml (from speechbrain)\n",
      "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.3.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.23.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from speechbrain) (23.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.11.3)\n",
      "Collecting sentencepiece (from speechbrain)\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m56.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from speechbrain) (2.0.1+cu118)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from speechbrain) (2.0.2+cu118)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from speechbrain) (4.66.1)\n",
      "Collecting huggingface-hub (from speechbrain)\n",
      "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m302.0/302.0 kB\u001B[0m \u001B[31m34.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->speechbrain) (3.27.7)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->speechbrain) (17.0.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain) (2023.6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain) (6.0.1)\n",
      "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain)\n",
      "  Downloading ruamel.yaml-0.17.35-py3-none-any.whl (112 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m112.9/112.9 kB\u001B[0m \u001B[31m15.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain)\n",
      "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m526.7/526.7 kB\u001B[0m \u001B[31m46.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->speechbrain) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->speechbrain) (1.3.0)\n",
      "Installing collected packages: sentencepiece, ruamel.yaml.clib, ruamel.yaml, huggingface-hub, hyperpyyaml, speechbrain\n",
      "Successfully installed huggingface-hub-0.18.0 hyperpyyaml-1.2.2 ruamel.yaml-0.17.35 ruamel.yaml.clib-0.2.8 sentencepiece-0.1.99 speechbrain-0.5.15\n"
     ]
    }
   ],
   "source": [
    "!pip install speechbrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYtBaWxqRUOV",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1697673997498,
     "user_tz": -480,
     "elapsed": 12256,
     "user": {
      "displayName": "lalitha ravi",
      "userId": "00357164084518936800"
     }
    },
    "outputId": "dedcbb20-9f89-482e-887c-e560e6ba2c92"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting textgrid\n",
      "  Downloading TextGrid-1.5-py3-none-any.whl (10.0 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.7/7.7 MB\u001B[0m \u001B[31m16.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
      "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.8/3.8 MB\u001B[0m \u001B[31m40.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m43.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.56.4)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.7.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.5.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.7)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (67.7.2)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m295.0/295.0 kB\u001B[0m \u001B[31m31.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Installing collected packages: textgrid, safetensors, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.18.0\n",
      "    Uninstalling huggingface-hub-0.18.0:\n",
      "      Successfully uninstalled huggingface-hub-0.18.0\n",
      "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 textgrid-1.5 tokenizers-0.14.1 transformers-4.34.1\n"
     ]
    }
   ],
   "source": [
    "!pip install textgrid transformers librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53nh8Xl--eZ4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import logging\n",
    "import speechbrain as sb\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "import librosa\n",
    "import csv\n",
    "from google.colab import drive, files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kiA9SjWIHOx5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1697674022568,
     "user_tz": -480,
     "elapsed": 18745,
     "user": {
      "displayName": "lalitha ravi",
      "userId": "00357164084518936800"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "19182edf-c74f-4ceb-e975-c78ff01d2520"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mount drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sikO-MV-Iv0V"
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1KP_dzhN-A7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1697674022568,
     "user_tz": -480,
     "elapsed": 5,
     "user": {
      "displayName": "lalitha ravi",
      "userId": "00357164084518936800"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5d5aa200-55c8-4e69-e6fe-9b783cce45b1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current Working Directory after change: /content/drive/MyDrive/CS5647_Project\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/content/drive/MyDrive/CS5647_Project'\n",
    "os.chdir(folder_path)\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Working Directory after change:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZQkBQKicOBmT"
   },
   "outputs": [],
   "source": [
    "from mpd_eval_v3 import MpdStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3meQIqYI1tr"
   },
   "outputs": [],
   "source": [
    "def make_attn_mask(wavs, wav_lens):\n",
    "    \"\"\"\n",
    "    wav_lens: relative lengths(i.e. 0-1) of a batch. shape: (bs, )\n",
    "    return a tensor of shape (bs, seq_len), representing mask on allowed positions.\n",
    "            1 for regular tokens, 0 for padded tokens\n",
    "    \"\"\"\n",
    "    abs_lens = (wav_lens*wavs.shape[1]).long()\n",
    "    attn_mask = wavs.new(wavs.shape).zero_().long()\n",
    "    for i in range(len(abs_lens)):\n",
    "        attn_mask[i, :abs_lens[i]] = 1\n",
    "    return attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MRjl6kGqI7Lr"
   },
   "outputs": [],
   "source": [
    "class ASR(sb.Brain):\n",
    "    def compute_forward(self, batch, stage):\n",
    "        \"Given an input batch it computes the phoneme probabilities.\"\n",
    "        batch = batch.to(self.device)\n",
    "        wavs, wav_lens = batch.sig\n",
    "        # phns_bos, _ = batch.phn_encoded_bos\n",
    "\n",
    "        if stage == sb.Stage.TRAIN:\n",
    "            if hasattr(self.hparams, \"augmentation\"):\n",
    "                wavs = self.hparams.augmentation(wavs, wav_lens)\n",
    "\n",
    "        # some wav2vec models (e.g. large-lv60) needs attention_mask\n",
    "        if self.modules.wav2vec2.feature_extractor.return_attention_mask:\n",
    "            attn_mask = make_attn_mask(wavs, wav_lens)\n",
    "            feats = self.modules.wav2vec2(wavs, attention_mask=attn_mask)\n",
    "        else:\n",
    "            attn_mask = None\n",
    "            feats = self.modules.wav2vec2(wavs)\n",
    "\n",
    "        x = self.modules.enc(feats)\n",
    "\n",
    "        # output layer for ctc log-probabilities\n",
    "        logits = self.modules.ctc_lin(x)\n",
    "        p_ctc = self.hparams.log_softmax(logits)\n",
    "\n",
    "        return p_ctc, wav_lens\n",
    "\n",
    "    def compute_objectives(self, predictions, batch, stage):\n",
    "        \"Given the network predictions and targets computed the NLL loss.\"\n",
    "\n",
    "        p_ctc, wav_lens = predictions\n",
    "\n",
    "        ids = batch.id\n",
    "        targets, target_lens = batch.phn_encoded_target\n",
    "        if stage != sb.Stage.TRAIN:\n",
    "            canonicals, canonical_lens = batch.phn_encoded_canonical\n",
    "            perceiveds, perceived_lens = batch.phn_encoded_perceived\n",
    "\n",
    "        loss_ctc = self.hparams.ctc_cost(p_ctc, targets, wav_lens, target_lens)\n",
    "        loss = loss_ctc\n",
    "\n",
    "        # Record losses for posterity\n",
    "        if stage != sb.Stage.TRAIN:\n",
    "            # Note: sb.decoders.ctc_greedy_decode will also remove padded tokens\n",
    "            # that is, it return a list of list with different lengths\n",
    "            sequence = sb.decoders.ctc_greedy_decode(\n",
    "                p_ctc, wav_lens, blank_id=self.hparams.blank_index\n",
    "            )\n",
    "            self.ctc_metrics.append(ids, p_ctc, targets, wav_lens, target_lens)\n",
    "\n",
    "            self.per_metrics.append(\n",
    "                ids=ids,\n",
    "                predict=sequence,\n",
    "                target=targets,\n",
    "                predict_len=None,\n",
    "                target_len=target_lens,\n",
    "                ind2lab=self.label_encoder.decode_ndim,\n",
    "            )\n",
    "            self.mpd_metrics.append(\n",
    "                ids=ids,\n",
    "                predict=sequence,\n",
    "                canonical=canonicals,\n",
    "                perceived=perceiveds,\n",
    "                predict_len=None,\n",
    "                canonical_len=canonical_lens,\n",
    "                perceived_len=perceived_lens,\n",
    "                ind2lab=self.label_encoder.decode_ndim,\n",
    "            )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def evaluate_batch(self, batch, stage):\n",
    "        \"\"\"Computations needed for validation/test batches\"\"\"\n",
    "        predictions = self.compute_forward(batch, stage=stage)\n",
    "        loss = self.compute_objectives(predictions, batch, stage=stage)\n",
    "        return loss.detach()\n",
    "\n",
    "    def on_stage_start(self, stage, epoch):\n",
    "        \"Gets called when a stage (either training, validation, test) starts.\"\n",
    "        self.ctc_metrics = self.hparams.ctc_stats()\n",
    "        if self.hparams.wav2vec2_specaug:\n",
    "            self.modules.wav2vec2.model.config.apply_spec_augment = True\n",
    "\n",
    "        if stage != sb.Stage.TRAIN:\n",
    "            self.modules.wav2vec2.model.config.apply_spec_augment = False\n",
    "            self.per_metrics = self.hparams.per_stats()\n",
    "            self.mpd_metrics = MpdStats()\n",
    "\n",
    "    def on_stage_end(self, stage, stage_loss, epoch):\n",
    "        \"\"\"Gets called at the end of a epoch.\"\"\"\n",
    "        if stage == sb.Stage.TRAIN:\n",
    "            self.train_loss = stage_loss\n",
    "        else:\n",
    "            per = self.per_metrics.summarize(\"error_rate\")\n",
    "            mpd_f1 = self.mpd_metrics.summarize(\"mpd_f1\")\n",
    "\n",
    "        if stage == sb.Stage.VALID:\n",
    "\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                stats_meta={\n",
    "                    \"epoch\": epoch,\n",
    "                    \"lr_adam\": self.adam_optimizer.param_groups[0][\"lr\"],\n",
    "                    \"lr_wav2vec\": self.wav2vec_optimizer.param_groups[0][\"lr\"],\n",
    "                },\n",
    "                train_stats={\"loss\": self.train_loss},\n",
    "                valid_stats={\n",
    "                    \"loss\": stage_loss,\n",
    "                    \"ctc_loss\": self.ctc_metrics.summarize(\"average\"),\n",
    "                    \"PER\": per,\n",
    "                    \"mpd_f1\": mpd_f1\n",
    "                },\n",
    "            )\n",
    "            self.checkpointer.save_and_keep_only(\n",
    "                meta={\"PER\": per, \"mpd_f1\": mpd_f1}, min_keys=[\"PER\"], max_keys=[\"mpd_f1\"]\n",
    "            )\n",
    "\n",
    "        if stage == sb.Stage.TEST:\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                stats_meta={\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
    "                test_stats={\"loss\": stage_loss, \"PER\": per, \"mpd_f1\": mpd_f1},\n",
    "            )\n",
    "            with open(self.hparams.wer_file, \"w\") as w:\n",
    "                w.write(\"CTC loss stats:\\n\")\n",
    "                self.ctc_metrics.write_stats(w)\n",
    "                w.write(\"\\nPER stats:\\n\")\n",
    "                self.per_metrics.write_stats(w)\n",
    "                print(\n",
    "                    \"CTC and PER stats written to file\",\n",
    "                    self.hparams.wer_file,\n",
    "                )\n",
    "            with open(self.hparams.mpd_file, \"w\") as m:\n",
    "                m.write(\"MPD results and stats:\\n\")\n",
    "                self.mpd_metrics.write_stats(m)\n",
    "                print(\n",
    "                    \"MPD results and stats written to file\",\n",
    "                    self.hparams.mpd_file,\n",
    "                )\n",
    "\n",
    "    def fit_batch(self, batch):\n",
    "        \"\"\"Fit one batch, override to do multiple updates.\n",
    "\n",
    "        The default implementation depends on a few methods being defined\n",
    "        with a particular behavior:\n",
    "\n",
    "        * ``compute_forward()``\n",
    "        * ``compute_objectives()``\n",
    "\n",
    "        Also depends on having optimizers passed at initialization.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        batch : list of torch.Tensors\n",
    "            Batch of data to use for training. Default implementation assumes\n",
    "            this batch has two elements: inputs and targets.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        detached loss\n",
    "        \"\"\"\n",
    "        # Managing automatic mixed precision\n",
    "        if self.auto_mix_prec:\n",
    "\n",
    "            self.wav2vec_optimizer.zero_grad()\n",
    "            self.adam_optimizer.zero_grad()\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = self.compute_forward(batch, sb.Stage.TRAIN)\n",
    "                loss = self.compute_objectives(outputs, batch, sb.Stage.TRAIN)\n",
    "\n",
    "            self.scaler.scale(loss).backward()\n",
    "            self.scaler.unscale_(self.wav2vec_optimizer)\n",
    "            self.scaler.unscale_(self.adam_optimizer)\n",
    "\n",
    "            if self.check_gradients(loss):\n",
    "                self.scaler.step(self.wav2vec_optimizer)\n",
    "                self.scaler.step(self.adam_optimizer)\n",
    "\n",
    "            self.scaler.update()\n",
    "        else:\n",
    "            outputs = self.compute_forward(batch, sb.Stage.TRAIN)\n",
    "\n",
    "            loss = self.compute_objectives(outputs, batch, sb.Stage.TRAIN)\n",
    "            # normalize the loss by gradient_accumulation step\n",
    "            (loss / self.hparams.gradient_accumulation).backward()\n",
    "\n",
    "            if self.step % self.hparams.gradient_accumulation == 0:\n",
    "                # gradient clipping & early stop if loss is not fini\n",
    "                if self.check_gradients(loss):\n",
    "                    self.wav2vec_optimizer.step()\n",
    "                    self.adam_optimizer.step()\n",
    "\n",
    "                self.wav2vec_optimizer.zero_grad()\n",
    "                self.adam_optimizer.zero_grad()\n",
    "\n",
    "        return loss.detach().cpu()\n",
    "\n",
    "    def init_optimizers(self):\n",
    "        \"Initializes the wav2vec2 optimizer and model optimizer\"\n",
    "        self.wav2vec_optimizer = self.hparams.wav2vec_opt_class(\n",
    "            self.modules.wav2vec2.model.parameters()\n",
    "        )\n",
    "        self.adam_optimizer = self.hparams.adam_opt_class(\n",
    "            self.hparams.model.parameters()\n",
    "        )\n",
    "\n",
    "        if self.checkpointer is not None:\n",
    "            self.checkpointer.add_recoverable(\n",
    "                \"wav2vec_opt\", self.wav2vec_optimizer\n",
    "            )\n",
    "            self.checkpointer.add_recoverable(\"adam_opt\", self.adam_optimizer)\n",
    "\n",
    "    def on_fit_start(self):\n",
    "        \"\"\"Gets called at the beginning of ``fit()``, on multiple processes\n",
    "        if ``distributed_count > 0`` and backend is ddp.\n",
    "\n",
    "        Default implementation compiles the jit modules, initializes\n",
    "        optimizers, and loads the latest checkpoint to resume training.\n",
    "        \"\"\"\n",
    "        # Run this *after* starting all processes since jit modules cannot be\n",
    "        # pickled.\n",
    "        self._compile_jit()\n",
    "\n",
    "        # Wrap modules with parallel backend after jit\n",
    "        self._wrap_distributed()\n",
    "\n",
    "        # Initialize optimizers after parameters are configured\n",
    "        self.init_optimizers()\n",
    "\n",
    "        # Load latest checkpoint to resume training if interrupted\n",
    "        ## NOTE: make sure to use the \"best\" model to continual training\n",
    "        ## so we set the `min_key` argument\n",
    "        if self.checkpointer is not None:\n",
    "            self.checkpointer.recover_if_possible(\n",
    "                device=torch.device(self.device),\n",
    "                min_key=\"PER\"\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nfd0QdzCeDuX"
   },
   "outputs": [],
   "source": [
    "def dataio_prep(hparams):\n",
    "    \"\"\"This function prepares the datasets to be used in the brain class.\n",
    "    It also defines the data processing pipeline through user-defined functions.\"\"\"\n",
    "    data_folder = hparams[\"data_folder_save\"]\n",
    "    # 1. Declarations:\n",
    "    train_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n",
    "        csv_path=hparams[\"train_annotation\"],\n",
    "        replacements={\"data_root\": data_folder},\n",
    "    )\n",
    "    if hparams[\"sorting\"] == \"ascending\":\n",
    "        # we sort training data to speed up training and get better results.\n",
    "        train_data = train_data.filtered_sorted(sort_key=\"duration\")\n",
    "        # when sorting do not shuffle in dataloader ! otherwise is pointless\n",
    "        hparams[\"train_dataloader_opts\"][\"shuffle\"] = False\n",
    "\n",
    "    elif hparams[\"sorting\"] == \"descending\":\n",
    "        train_data = train_data.filtered_sorted(\n",
    "            sort_key=\"duration\", reverse=True\n",
    "        )\n",
    "        # when sorting do not shuffle in dataloader ! otherwise is pointless\n",
    "        hparams[\"train_dataloader_opts\"][\"shuffle\"] = False\n",
    "\n",
    "    elif hparams[\"sorting\"] == \"random\":\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            \"sorting must be random, ascending or descending\"\n",
    "        )\n",
    "\n",
    "    valid_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n",
    "        csv_path=hparams[\"valid_annotation\"],\n",
    "        replacements={\"data_root\": data_folder},\n",
    "    )\n",
    "    valid_data = valid_data.filtered_sorted(sort_key=\"duration\")\n",
    "\n",
    "    test_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n",
    "        csv_path=hparams[\"test_annotation\"],\n",
    "        replacements={\"data_root\": data_folder},\n",
    "    )\n",
    "    test_data = test_data.filtered_sorted(sort_key=\"duration\")\n",
    "\n",
    "    datasets = [train_data, valid_data, test_data]\n",
    "    label_encoder = sb.dataio.encoder.CTCTextEncoder()\n",
    "\n",
    "    # 2. Define audio pipeline:\n",
    "    @sb.utils.data_pipeline.takes(\"wav\")\n",
    "    @sb.utils.data_pipeline.provides(\"sig\")\n",
    "    def audio_pipeline(wav):\n",
    "        # sig = sb.dataio.dataio.read_audio(wav)\n",
    "        # # sample rate change to 16000, e,g, using librosa\n",
    "        # sig = torch.Tensor(librosa.core.load(wav, hparams[\"sample_rate\"])[0])\n",
    "        # Use wav2vec processor to do normalization\n",
    "        sig = hparams[\"wav2vec2\"].feature_extractor(\n",
    "            librosa.core.load(wav, sr=hparams[\"sample_rate\"])[0],\n",
    "            sampling_rate=hparams[\"sample_rate\"],\n",
    "        ).input_values[0]\n",
    "        sig = torch.Tensor(sig)\n",
    "        return sig\n",
    "\n",
    "    sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline)\n",
    "\n",
    "    # 3. Define text pipeline:\n",
    "    @sb.utils.data_pipeline.takes(\"perceived_train_target\")\n",
    "    @sb.utils.data_pipeline.provides(\n",
    "        \"phn_list_target\",\n",
    "        \"phn_encoded_list_target\",\n",
    "        \"phn_encoded_target\",\n",
    "    )\n",
    "    def text_pipeline_train(phn):\n",
    "        phn_list = phn.strip().split()\n",
    "        yield phn_list\n",
    "        phn_encoded_list = label_encoder.encode_sequence(phn_list)\n",
    "        yield phn_encoded_list\n",
    "        phn_encoded = torch.LongTensor(phn_encoded_list)\n",
    "        yield phn_encoded\n",
    "\n",
    "    @sb.utils.data_pipeline.takes(\"perceived_train_target\", \"canonical_aligned\", \"perceived_aligned\")\n",
    "    @sb.utils.data_pipeline.provides(\n",
    "        \"phn_list_target\",\n",
    "        \"phn_encoded_list_target\",\n",
    "        \"phn_encoded_target\",\n",
    "        \"phn_list_canonical\",\n",
    "        \"phn_encoded_list_canonical\",\n",
    "        \"phn_encoded_canonical\",\n",
    "        \"phn_list_perceived\",\n",
    "        \"phn_encoded_list_perceived\",\n",
    "        \"phn_encoded_perceived\",\n",
    "    )\n",
    "    def text_pipeline_test(target, canonical, perceived):\n",
    "        phn_list_target = target.strip().split()\n",
    "        yield phn_list_target\n",
    "        phn_encoded_list_target = label_encoder.encode_sequence(phn_list_target)\n",
    "        yield phn_encoded_list_target\n",
    "        phn_encoded_target = torch.LongTensor(phn_encoded_list_target)\n",
    "        yield phn_encoded_target\n",
    "        phn_list_canonical = canonical.strip().split()\n",
    "        yield phn_list_canonical\n",
    "        phn_encoded_list_canonical = label_encoder.encode_sequence(phn_list_canonical)\n",
    "        yield phn_encoded_list_canonical\n",
    "        phn_encoded_canonical = torch.LongTensor(phn_encoded_list_canonical)\n",
    "        yield phn_encoded_canonical\n",
    "        phn_list_perceived = perceived.strip().split()\n",
    "        yield phn_list_perceived\n",
    "        phn_encoded_list_perceived = label_encoder.encode_sequence(phn_list_perceived)\n",
    "        yield phn_encoded_list_perceived\n",
    "        phn_encoded_perceived = torch.LongTensor(phn_encoded_list_perceived)\n",
    "        yield phn_encoded_perceived\n",
    "\n",
    "    sb.dataio.dataset.add_dynamic_item([train_data], text_pipeline_train)\n",
    "    sb.dataio.dataset.add_dynamic_item([valid_data, test_data], text_pipeline_test)\n",
    "\n",
    "    # 3. Fit encoder:\n",
    "    # Load or compute the label encoder\n",
    "    lab_enc_file = os.path.join(hparams[\"save_folder\"], \"label_encoder.txt\")\n",
    "    special_labels = {\n",
    "        \"blank_label\": hparams[\"blank_index\"],\n",
    "    }\n",
    "    label_encoder.load_or_create(\n",
    "        path=lab_enc_file,\n",
    "        from_didatasets=[train_data],\n",
    "        output_key=\"phn_list_target\",\n",
    "        special_labels=special_labels,\n",
    "        sequence_input=True,\n",
    "    )\n",
    "\n",
    "    # 4. Set output:\n",
    "    sb.dataio.dataset.set_output_keys(\n",
    "        [train_data],\n",
    "        [\"id\", \"sig\", \"phn_encoded_target\"],\n",
    "    )\n",
    "    sb.dataio.dataset.set_output_keys(\n",
    "        [valid_data, test_data],\n",
    "        [\"id\", \"sig\", \"phn_encoded_target\", \"phn_encoded_canonical\", \"phn_encoded_perceived\"],\n",
    "    )\n",
    "\n",
    "    return train_data, valid_data, test_data, label_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yVsbqzMyJBRL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1697674039807,
     "user_tz": -480,
     "elapsed": 16267,
     "user": {
      "displayName": "lalitha ravi",
      "userId": "00357164084518936800"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5b967694-baf0-4833-fd67-beed3b4300de"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py:380: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "WARNING:speechbrain.lobes.models.huggingface_wav2vec:speechbrain.lobes.models.huggingface_wav2vec - wav2vec 2.0 feature extractor is frozen.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "speechbrain.core - Beginning experiment!\n",
      "speechbrain.core - Experiment folder: results/wav2vec2-base_ctc/\n",
      "speechbrain.dataio.encoder - Load called, but CTCTextEncoder is not empty. Loaded data will overwrite everything. This is normal if there is e.g. an unk label defined at init.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hparams_file = '/content/drive/MyDrive/CS5647_Project/hparams/train.yaml'\n",
    "\n",
    "# Load hyperparameters file with command-line overrides\n",
    "with open(hparams_file) as fin:\n",
    "    hparams = load_hyperpyyaml(fin)\n",
    "\n",
    "\n",
    "# Create experiment directory\n",
    "sb.create_experiment_directory(\n",
    "    experiment_directory=hparams[\"output_folder\"],\n",
    "    hyperparams_to_save=hparams_file,\n",
    ")\n",
    "\n",
    "# Dataset IO prep: creating Dataset objects and proper encodings for phones\n",
    "train_data, valid_data, test_data, label_encoder = dataio_prep(hparams)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QQHyc36_74th",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1697677051760,
     "user_tz": -480,
     "elapsed": 3011973,
     "user": {
      "displayName": "lalitha ravi",
      "userId": "00357164084518936800"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1f2e5bd8-3432-4ff4-9682-9ab8c080fdbc"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "speechbrain.core - Info: auto_mix_prec arg from hparam file is used\n",
      "speechbrain.core - 90.6M trainable parameters in ASR\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "speechbrain.utils.checkpoints - Loading a checkpoint from results/wav2vec2-base_ctc/save/CKPT+2023-10-18+19-25-36+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 32\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "                                      /usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads."
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r  0%|          | 0/38 [00:44<?, ?it/s]/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "                                      /usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/38 [00:44<?, ?it/s]/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r  0%|          | 0/38 [00:45<?, ?it/s]/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 38/38 [11:01<00:00, 17.41s/it, train_loss=0.648]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r  0%|          | 0/19 [00:22<?, ?it/s]/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/19 [00:22<?, ?it/s]/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r  0%|          | 0/19 [00:22<?, ?it/s]/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r  0%|          | 0/19 [00:22<?, ?it/s]/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r  0%|          | 0/19 [00:22<?, ?it/s]/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r  0%|          | 0/19 [00:23<?, ?it/s]/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r  0%|          | 0/19 [00:23<?, ?it/s]/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 19/19 [01:44<00:00,  5.49s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "speechbrain.utils.train_logger - epoch: 32, lr_adam: 3.00e-04, lr_wav2vec: 1.00e-05 - train loss: 6.48e-01 - valid loss: 5.99e-01, valid ctc_loss: 5.98e-01, valid PER: 18.36, valid mpd_f1: 4.28e-01\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/wav2vec2-base_ctc/save/CKPT+2023-10-19+00-20-18+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in results/wav2vec2-base_ctc/save/CKPT+2023-10-18+19-25-36+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 33\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 38/38 [10:12<00:00, 16.13s/it, train_loss=0.606]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 19/19 [01:29<00:00,  4.71s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "speechbrain.utils.train_logger - epoch: 33, lr_adam: 3.00e-04, lr_wav2vec: 1.00e-05 - train loss: 6.06e-01 - valid loss: 5.90e-01, valid ctc_loss: 5.89e-01, valid PER: 18.06, valid mpd_f1: 4.23e-01\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/wav2vec2-base_ctc/save/CKPT+2023-10-19+00-32-03+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 34\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 38/38 [10:19<00:00, 16.32s/it, train_loss=0.583]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 19/19 [01:27<00:00,  4.58s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "speechbrain.utils.train_logger - epoch: 34, lr_adam: 3.00e-04, lr_wav2vec: 1.00e-05 - train loss: 5.83e-01 - valid loss: 5.91e-01, valid ctc_loss: 5.90e-01, valid PER: 18.00, valid mpd_f1: 4.33e-01\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/wav2vec2-base_ctc/save/CKPT+2023-10-19+00-43-53+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in results/wav2vec2-base_ctc/save/CKPT+2023-10-19+00-32-03+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in results/wav2vec2-base_ctc/save/CKPT+2023-10-19+00-20-18+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 35\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 38/38 [09:56<00:00, 15.70s/it, train_loss=0.584]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 19/19 [01:26<00:00,  4.53s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "speechbrain.utils.train_logger - epoch: 35, lr_adam: 3.00e-04, lr_wav2vec: 1.00e-05 - train loss: 5.84e-01 - valid loss: 5.90e-01, valid ctc_loss: 5.89e-01, valid PER: 17.92, valid mpd_f1: 4.26e-01\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/wav2vec2-base_ctc/save/CKPT+2023-10-19+00-55-18+00\n",
      "speechbrain.utils.checkpoints - Loading a checkpoint from results/wav2vec2-base_ctc/save/CKPT+2023-10-19+00-55-18+00\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numexpr.utils - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 300/300 [02:08<00:00,  2.33it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "speechbrain.utils.train_logger - Epoch loaded: 35 - test loss: 7.20e-01, test PER: 19.58, test mpd_f1: 3.75e-01\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CTC and PER stats written to file results/wav2vec2-base_ctc//wer.txt\n",
      "MPD results and stats written to file results/wav2vec2-base_ctc//mpd.txt\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7197455436487993"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Trainer initialization\n",
    "asr_brain = ASR(\n",
    "    modules=hparams[\"modules\"],\n",
    "    hparams=hparams,\n",
    "    checkpointer=hparams[\"checkpointer\"],\n",
    ")\n",
    "asr_brain.label_encoder = label_encoder\n",
    "\n",
    "# Training/validation loop\n",
    "asr_brain.fit(\n",
    "    asr_brain.hparams.epoch_counter,\n",
    "    train_data,\n",
    "    valid_data,\n",
    "    train_loader_kwargs=hparams[\"train_dataloader_opts\"],\n",
    "    valid_loader_kwargs=hparams[\"valid_dataloader_opts\"],\n",
    "\n",
    ")\n",
    "\n",
    "# Test\n",
    "asr_brain.evaluate(\n",
    "    test_data,\n",
    "    min_key=\"PER\",\n",
    "    test_loader_kwargs=hparams[\"test_dataloader_opts\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "gpuType": "V100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
