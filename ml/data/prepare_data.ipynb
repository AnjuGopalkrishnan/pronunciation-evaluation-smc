{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# Install speechbrain\n","%%capture\n","# Local installation\n","!git clone https://github.com/speechbrain/speechbrain/\n","%cd /content/drive/MyDrive/CS5647_Project/speechbrain/\n","!pip install -r requirements.txt\n","!pip install -e .\n","!pip install textgrid transformers librosa\n"],"metadata":{"id":"yBfc1JoSqZBx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","\n","# Add a new path to the PYTHONPATH\n","sys.path.append('/content/drive/MyDrive/CS5647_Project/speechbrain/')"],"metadata":{"id":"KUSPN_-Lqa_7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install speechbrain"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aGsETHOtqciF","executionInfo":{"status":"ok","timestamp":1697633253554,"user_tz":-480,"elapsed":5720,"user":{"displayName":"lalitha ravi","userId":"00357164084518936800"}},"outputId":"cefc019c-5697-4edd-c9e8-ba6c387d5151"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: speechbrain in /usr/local/lib/python3.10/dist-packages (0.5.14)\n","Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.2.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.3.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from speechbrain) (23.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.11.3)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from speechbrain) (0.1.99)\n","Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from speechbrain) (2.0.1+cu118)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from speechbrain) (2.0.2+cu118)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from speechbrain) (4.66.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from speechbrain) (0.17.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->speechbrain) (3.27.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->speechbrain) (17.0.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain) (6.0.1)\n","Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.10/dist-packages (from hyperpyyaml->speechbrain) (0.17.35)\n","Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain) (0.2.8)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->speechbrain) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->speechbrain) (1.3.0)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a9RRW9Nf6z_8"},"outputs":[],"source":["#import necessary libraries\n","from google.colab import drive, files\n","import torch\n","import os\n","import csv\n","from glob import glob\n","from textgrid import TextGrid, IntervalTier\n","from speechbrain.dataio.dataio import read_audio\n","import re\n","import copy\n","from collections import defaultdict"]},{"cell_type":"code","source":["# Mount drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ONdD6xLL7EXZ","executionInfo":{"status":"ok","timestamp":1697633262159,"user_tz":-480,"elapsed":4542,"user":{"displayName":"lalitha ravi","userId":"00357164084518936800"}},"outputId":"986f3ed4-dd91-45fd-b519-1618b6594266"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"IJtj47CO7LgA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["folder_path = '/content/drive/MyDrive/CS5647_Project'\n","os.chdir(folder_path)\n","current_directory = os.getcwd()\n","print(\"Current Working Directory after change:\", current_directory)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gf8MwtWu7UwY","executionInfo":{"status":"ok","timestamp":1697633262159,"user_tz":-480,"elapsed":8,"user":{"displayName":"lalitha ravi","userId":"00357164084518936800"}},"outputId":"79e3f4c9-23de-4db7-ad8f-4f582ba75547"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Current Working Directory after change: /content/drive/MyDrive/CS5647_Project\n"]}]},{"cell_type":"code","source":["dataset_path = '/content/drive/MyDrive/CS5647_Project/dataset'\n","speaker_ids = ['ASI', 'RRBI','SVBI','TNI', 'BWC', 'LXC', 'NCC', 'TXHC']\n","csv_data_path = '/content/drive/MyDrive/CS5647_Project/data/processed_data.csv'"],"metadata":{"id":"HuMjWeIIC7eJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["AUDIO_SAMPLE_RATE = 44100\n","phn_set=\"/content/drive/MyDrive/CS5647_Project/arpa_phonemes\"\n","def process_arpa_phoneme(path):\n","    with open(path, 'r') as f:\n","        lines = f.readlines()\n","    arpa_phonemes= []\n","    for line in lines:\n","        items = line.strip().split()\n","        arpa_phonemes.append(items[0])\n","    return arpa_phonemes\n","\n"],"metadata":{"id":"bDoawwDtEMAs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ARPA_PHONEMES = process_arpa_phoneme(phn_set)\n"],"metadata":{"id":"uNMcf3qghzbw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def is_sil(s: str) -> bool:\n","    \"\"\"Test if the input string represents silence.\n","    Args:\n","        s: A phoneme label.\n","    Returns:\n","        True if is silence, otherwise False.\n","    \"\"\"\n","    if s.lower() in {\"sil\", \"sp\", \"spn\", \"pau\", \"\"}:\n","        return True\n","    else:\n","        return False"],"metadata":{"id":"mAMiYaskjGOY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def normalize_phone(s: str, is_rm_annotation=True, is_phoneme_canonical=True,keep_artificial_sil=False) -> str:\n","  \"\"\"Normalize phoneme labels to lower case, stress-free form.\n","    This will also deal with L2-ARCTIC annotations.\n","    Args:\n","        s: A phoneme annotation.\n","        is_rm_annotation: [optional] Only return the canonical pronunciation if\n","        set to true, otherwise will keep the annotations.\n","        is_phoneme_canonical: [optional] If set to true, return canonical phoneme; otherwise\n","        return perceived phoneme.\n","        keep_artificial_sil: If true, will keep the artificial sil produced by the way L2ARCTIC was annotated.\n","                            If false, will not have the sil\n","                            e.g. when false, 'ah, sil, d' canonical: ah, perceived: None\n","                                 when true, 'ah, sil, d' canonical: ah, perceived: sil\n","    Returns:\n","        Normalized phoneme (canonical pronunciation or with annotations).\n","  \"\"\"\n","  t = s.lower()\n","  pattern = re.compile(r\"[^a-z,]\")\n","  parse_tag = pattern.sub(\"\", t)\n","  if is_sil(parse_tag):\n","      return \"sil\"\n","  if len(parse_tag) == 0:\n","      raise ValueError(\"Input %s is invalid.\", s)\n","  if len(parse_tag.split(\",\")) == 1:\n","      if parse_tag.split(\",\")[0] == 'ax':\n","          return 'ah'\n","      else:\n","          return parse_tag.split(\",\")[0]\n","  if is_rm_annotation:\n","      # This handles the L2-ARCTIC annotations, here we extract the canonical\n","      # pronunciation\n","      if keep_artificial_sil:\n","          if is_phoneme_canonical:\n","              return parse_tag.split(\",\")[0]\n","          else:\n","              return parse_tag.split(\",\")[1]\n","      elif not keep_artificial_sil:\n","          if is_phoneme_canonical:\n","              if parse_tag.split(\",\")[2] in ['s', 'd']:\n","                  return parse_tag.split(\",\")[0]\n","              elif parse_tag.split(\",\")[2] == 'a':\n","                  return None\n","          else:\n","              if parse_tag.split(\",\")[2] in ['s', 'a']:\n","                  return parse_tag.split(\",\")[1]\n","              elif parse_tag.split(\",\")[2] == 'd':\n","                  return None\n","  else:\n","      return parse_tag\n","\n","\n","\n","\n"],"metadata":{"id":"W7UtCgp4imad"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def normalize_tier_mark(tier: IntervalTier,\n","                        mode=\"NormalizePhoneCanonical\", keep_artificial_sil=False) -> IntervalTier:\n","    \"\"\"Normalize the marks of an IntervalTier.\n","    Refer to the code for supported modes.\n","    Args:\n","        tier: An IntervalTier object.\n","        mode: The filter function for each mark in the tier.\n","    Returns:\n","        tier: Mark-normalized tier.\n","    \"\"\"\n","    tier = copy.deepcopy(tier)\n","    tier_out = IntervalTier()\n","    if mode not in {\"NormalizePhoneCanonical\",\n","                    \"NormalizePhonePerceived\",\n","                    \"NormalizePhoneAnnotation\",\n","                    \"NormalizeWord\"}:\n","        raise ValueError(\"Mode %s is not valid.\", mode)\n","    for each_interval in tier.intervals:\n","        if mode == \"NormalizePhoneCanonical\":\n","            # Only keep the canonical pronunciation.\n","            p = normalize_phone(each_interval.mark, True, True, keep_artificial_sil)\n","        elif mode == \"NormalizePhonePerceived\":\n","            # Only keep the perceived pronunciation.\n","            p = normalize_phone(each_interval.mark, True, False, keep_artificial_sil)\n","        elif mode == \"NormalizePhoneAnnotation\":\n","            # Keep the annotations.\n","            p = normalize_phone(each_interval.mark, False)\n","        elif mode == \"NormalizeWord\":\n","            p = normalize_word(each_interval.mark)\n","\n","        if p is None:\n","            continue\n","        if p == 'ax':\n","            p = 'ah'\n","        each_interval.mark = p\n","        assert p in ARPA_PHONEMES + [\"err\"], pdb.set_trace()\n","        tier_out.addInterval(each_interval)\n","    return tier_out\n"],"metadata":{"id":"G_1rypj7fLRm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tier_to_list(tier):\n","    return [interval.mark for interval in tier]"],"metadata":{"id":"ZSuHLh6IlJ3b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def remove_repetitive_sil(phone_list):\n","    # Filtering out consecutive silences by applying a mask with `True` marking\n","    # which sils to remove\n","    # e.g.\n","    # phone_list          [  \"a\", \"sil\", \"sil\",  \"sil\",   \"b\"]\n","    # ---\n","    # create:\n","    # remove_sil_mask   [False,  True,  True,  False,  False]\n","    # ---\n","    # so end result is:\n","    # phone_list [\"a\", \"sil\", \"b\"]\n","\n","    remove_sil_mask = [True if x == \"sil\" else False for x in phone_list]\n","\n","    for i, val in enumerate(remove_sil_mask):\n","        if val is True:\n","            if i == len(remove_sil_mask) - 1:\n","                remove_sil_mask[i] = False\n","            elif remove_sil_mask[i + 1] is False:\n","                remove_sil_mask[i] = False\n","\n","    phone_list = [\n","        phon for i, phon in enumerate(phone_list) if not remove_sil_mask[i]\n","    ]\n","    return phone_list"],"metadata":{"id":"SO4bXTJallgM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_phonemes(tg, keep_artificial_sil=False, rm_repetitive_sil=True):\n","    phone_tier = tg.getFirst(\"phones\")\n","    perceived_phones = normalize_tier_mark(phone_tier, \"NormalizePhonePerceived\", keep_artificial_sil)\n","    canonical_phones = normalize_tier_mark(phone_tier, \"NormalizePhoneCanonical\", keep_artificial_sil)\n","    canonical_phones = tier_to_list(canonical_phones)\n","    perceived_phones = tier_to_list(perceived_phones)\n","    if keep_artificial_sil:\n","        # when we preserve the artificial sils, the canonical phones and\n","        # perceived phones should be perfectly aligned\n","        assert len(canonical_phones) == len(perceived_phones)\n","    if rm_repetitive_sil:\n","        canonical_phones = remove_repetitive_sil(canonical_phones)\n","        perceived_phones = remove_repetitive_sil(perceived_phones)\n","    return \" \".join(canonical_phones), \" \".join(perceived_phones)\n"],"metadata":{"id":"43oF_uPjcFFI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def process_annotation_data(tg, wav_file, text_file, spkr):\n","  row_data = {}\n","  row_data['ID'] = wav_file\n","  row_data[\"wav\"] = wav_file\n","  # Reading the signal (to retrieve duration in seconds)\n","  signal = read_audio(wav_file)\n","  duration = len(signal) / AUDIO_SAMPLE_RATE\n","  row_data[\"duration\"] = duration\n","  row_data[\"spk_id\"] = spkr\n","  ## To keep original human annotation, set `keep_artifical_sil=True`, `rm_repetitive_sil=False`\n","  ## this preserve the original alignment within the annotations\n","  cano_phns_align, perc_phns_align = get_phonemes(tg, keep_artificial_sil=True, rm_repetitive_sil=False)\n","  row_data[\"canonical_aligned\"] = cano_phns_align\n","  row_data[\"perceived_aligned\"] = perc_phns_align\n","  ## To get training target phones, set `keep_artifical_sil=False`, `rm_repetitive_sil=True`\n","  ## this apply some preprocessing on the perceived phones, i.e. rm artifical and repetitive sil\n","  _, target_phns = get_phonemes(tg, keep_artificial_sil=False, rm_repetitive_sil=True)\n","  row_data[\"perceived_train_target\"] = target_phns\n","\n","  with open(text_file, \"r\") as reader:\n","      text = reader.readline()\n","  row_data[\"wrd\"] = text\n","  return row_data\n","\n","\n","\n"],"metadata":{"id":"Q3TL-xiNaANi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_csv(base_dir, output_csv):\n","  print(f\"Creating {output_csv}\")\n","  with open(output_csv, mode='w', newline=\"\") as csv_f:\n","    fieldnames = [\"ID\", \"wav\", \"duration\", \"spk_id\",\"canonical_aligned\",\n","                         \"perceived_aligned\", \"perceived_train_target\", \"wrd\"]\n","    csv_writer = csv.DictWriter(csv_f, fieldnames=fieldnames, delimiter=\",\", quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n","    csv_writer.writeheader()\n","\n","\n","    for spkr in speaker_ids:\n","      wav_dir = os.path.join(base_dir, spkr, 'wav')\n","      annotation_dir = os.path.join(base_dir, spkr, 'annotation')\n","      transcript_dir = os.path.join(base_dir, spkr, 'transcript')\n","\n","      for tg_file in glob(os.path.join(annotation_dir, \"*.TextGrid\")):\n","        tg = TextGrid()\n","        try:\n","          tg.read(tg_file)\n","        except ValueError:\n","          continue\n","        base_name = os.path.basename(tg_file).split(\".\")[0]\n","        wav_file = os.path.join(wav_dir, base_name + \".wav\")\n","        text_file = os.path.join(transcript_dir, base_name + '.txt')\n","        row_data = process_annotation_data(tg, wav_file, text_file, spkr)\n","        csv_writer.writerow(row_data)\n","      print(f\"Succescuffly created for {spkr}!!\")\n","\n","\n","\n","\n","\n"],"metadata":{"id":"M7aTkl0BLOEx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prepare_l2arctic(base_dir, output_csv):\n","  # if os.path.exists(output_csv):\n","  #   print(f\"CSV file '{output_csv}' already exists. Skipping data preparation.\")\n","  #   return\n","  # else:\n","  create_csv(base_dir, output_csv)\n","\n","\n","\n"],"metadata":{"id":"H-ROYLJa-CvD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prepare_l2arctic(base_dir=dataset_path,output_csv= csv_data_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0GGEpGRpCzH8","executionInfo":{"status":"ok","timestamp":1697634063057,"user_tz":-480,"elapsed":800903,"user":{"displayName":"lalitha ravi","userId":"00357164084518936800"}},"outputId":"d2748145-b77f-48f0-a474-15f7f3dce8ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating /content/drive/MyDrive/CS5647_Project/data/processed_data.csv\n","Succescuffly created for ASI!!\n","Succescuffly created for RRBI!!\n","Succescuffly created for SVBI!!\n","Succescuffly created for TNI!!\n","Succescuffly created for BWC!!\n","Succescuffly created for LXC!!\n","Succescuffly created for NCC!!\n","Succescuffly created for TXHC!!\n"]}]}]}