{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-processing done!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "data_dir = 'data'\n",
    "\n",
    "# List to store data dictionaries\n",
    "data_list = []\n",
    "\n",
    "# Define audio and feature parameters\n",
    "sample_rate = 16000 \n",
    "n_mfcc = 13 \n",
    "n_fft = 400 \n",
    "hop_length = 160 \n",
    "\n",
    "# Walk through the main data directory\n",
    "for speaker_dir in os.listdir(data_dir):\n",
    "    if os.path.isdir(os.path.join(data_dir, speaker_dir)):\n",
    "        speaker_path = os.path.join(data_dir, speaker_dir)\n",
    "        transcripts_dir = os.path.join(speaker_path, speaker_dir, 'transcript')\n",
    "        # For each speaker, traverse their directory\n",
    "        for root, _, files in os.walk(speaker_path):\n",
    "            for file in files:\n",
    "                if file.endswith('.wav'):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    \n",
    "                    # Extract the transcript from the transcripts directory\n",
    "                    base_filename, _ = os.path.splitext(file)\n",
    "                    transcript_path = os.path.join(transcripts_dir, f'{base_filename}.txt')\n",
    "                    \n",
    "                    if os.path.isfile(transcript_path):\n",
    "                        with open(transcript_path, 'r', encoding='utf-8') as file:\n",
    "                            transcript = file.read().strip()\n",
    "                    else:\n",
    "                        transcript = \"Transcript not found\"\n",
    "                    \n",
    "                    # Load the audio file\n",
    "                    audio, _ = librosa.load(file_path, sr=sample_rate)\n",
    "                    \n",
    "                    # Extract MFCC features\n",
    "                    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "                    \n",
    "                    # Append the data as a dictionary to the list\n",
    "                    data_list.append({'file_path': file_path, 'transcript': transcript, 'mfcc_features': mfccs.T})\n",
    "                    \n",
    "metadata = pd.DataFrame(data_list)\n",
    "\n",
    "# Saving the metadata to a CSV file for reference\n",
    "metadata.to_csv('metadata.csv', index=False)\n",
    "print(\"pre-processing done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metadata = pd.read_csv('metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data = train_test_split(metadata, test_size=0.2, random_state=42)\n",
    "val_data, test_data = train_test_split(val_data, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = list(train_data['mfcc_features'])\n",
    "val_features = list(val_data['mfcc_features'])\n",
    "test_features = list(test_data['mfcc_features'])\n",
    "\n",
    "train_labels = list(train_data['transcript'])\n",
    "val_labels = list(val_data['transcript'])\n",
    "test_labels = list(test_data['transcript'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: One-hot encode labels for classification\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "label_encoder = LabelBinarizer()\n",
    "train_labels = label_encoder.fit_transform(train_labels)\n",
    "val_labels = label_encoder.transform(val_labels)\n",
    "test_labels = label_encoder.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
