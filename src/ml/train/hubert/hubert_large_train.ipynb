{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kJErFaz_Eib4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWkjs_8PHcBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75fc4695-9a78-4d7f-a7cd-f7db96773240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: speechbrain in /usr/local/lib/python3.10/dist-packages (0.5.16)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from speechbrain) (23.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.11.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from speechbrain) (0.1.99)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from speechbrain) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from speechbrain) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from speechbrain) (4.66.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from speechbrain) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain) (6.0.1)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.10/dist-packages (from hyperpyyaml->speechbrain) (0.18.5)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain) (0.2.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->speechbrain) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->speechbrain) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install speechbrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYtBaWxqRUOV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e2624a0-9f02-45de-ece4-c35178571647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textgrid in /usr/local/lib/python3.10/dist-packages (1.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.7)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n"
          ]
        }
      ],
      "source": [
        "!pip install textgrid transformers librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53nh8Xl--eZ4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import logging\n",
        "import speechbrain as sb\n",
        "from hyperpyyaml import load_hyperpyyaml\n",
        "import librosa\n",
        "import csv\n",
        "from google.colab import drive, files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiA9SjWIHOx5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2499d9cd-4ff2-4ae3-9832-bdc7df6a817e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sikO-MV-Iv0V"
      },
      "outputs": [],
      "source": [
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1KP_dzhN-A7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8633ffb5-eff7-466e-8a52-a91a313752e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Working Directory after change: /content/drive/MyDrive/CS5647_Project\n"
          ]
        }
      ],
      "source": [
        "folder_path = '/content/drive/MyDrive/CS5647_Project'\n",
        "os.chdir(folder_path)\n",
        "current_directory = os.getcwd()\n",
        "print(\"Current Working Directory after change:\", current_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQkBQKicOBmT"
      },
      "outputs": [],
      "source": [
        "from mpd_eval_v3 import MpdStats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3meQIqYI1tr"
      },
      "outputs": [],
      "source": [
        "def make_attn_mask(wavs, wav_lens):\n",
        "    \"\"\"\n",
        "    wav_lens: relative lengths(i.e. 0-1) of a batch. shape: (bs, )\n",
        "    return a tensor of shape (bs, seq_len), representing mask on allowed positions.\n",
        "            1 for regular tokens, 0 for padded tokens\n",
        "    \"\"\"\n",
        "    abs_lens = (wav_lens*wavs.shape[1]).long()\n",
        "    attn_mask = wavs.new(wavs.shape).zero_().long()\n",
        "    for i in range(len(abs_lens)):\n",
        "        attn_mask[i, :abs_lens[i]] = 1\n",
        "    return attn_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRjl6kGqI7Lr"
      },
      "outputs": [],
      "source": [
        "class ASR(sb.Brain):\n",
        "    def _compile_jit(self):\n",
        "        for module in self.modules:\n",
        "            if hasattr(module, \"_compile_jit\"):\n",
        "                module._compile_jit()\n",
        "\n",
        "    def compute_forward(self, batch, stage):\n",
        "        \"Given an input batch it computes the phoneme probabilities.\"\n",
        "        batch = batch.to(self.device)\n",
        "        wavs, wav_lens = batch.sig\n",
        "        # phns_bos, _ = batch.phn_encoded_bos\n",
        "\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            if hasattr(self.hparams, \"augmentation\"):\n",
        "                wavs = self.hparams.augmentation(wavs, wav_lens)\n",
        "\n",
        "        # some wav2vec models (e.g. large-lv60) needs attention_mask\n",
        "        # if self.modules.wav2vec2.feature_extractor.return_attention_mask:\n",
        "        #     attn_mask = make_attn_mask(wavs, wav_lens)\n",
        "        #     feats = self.modules.wav2vec2(wavs, attention_mask=attn_mask)\n",
        "        # else:\n",
        "        #     attn_mask = None\n",
        "        #     feats = self.modules.wav2vec2(wavs)\n",
        "        feats = self.modules.wav2vec2(wavs)\n",
        "        x = self.modules.enc(feats)\n",
        "\n",
        "        # output layer for ctc log-probabilities\n",
        "        logits = self.modules.ctc_lin(x)\n",
        "        p_ctc = self.hparams.log_softmax(logits)\n",
        "\n",
        "        return p_ctc, wav_lens\n",
        "\n",
        "    def compute_objectives(self, predictions, batch, stage):\n",
        "        \"Given the network predictions and targets computed the NLL loss.\"\n",
        "\n",
        "        p_ctc, wav_lens = predictions\n",
        "\n",
        "        ids = batch.id\n",
        "        targets, target_lens = batch.phn_encoded_target\n",
        "        if stage != sb.Stage.TRAIN:\n",
        "            canonicals, canonical_lens = batch.phn_encoded_canonical\n",
        "            perceiveds, perceived_lens = batch.phn_encoded_perceived\n",
        "\n",
        "        loss_ctc = self.hparams.ctc_cost(p_ctc, targets, wav_lens, target_lens)\n",
        "        loss = loss_ctc\n",
        "\n",
        "        # Record losses for posterity\n",
        "        if stage != sb.Stage.TRAIN:\n",
        "            # Note: sb.decoders.ctc_greedy_decode will also remove padded tokens\n",
        "            # that is, it return a list of list with different lengths\n",
        "            sequence = sb.decoders.ctc_greedy_decode(\n",
        "                p_ctc, wav_lens, blank_id=self.hparams.blank_index\n",
        "            )\n",
        "            self.ctc_metrics.append(ids, p_ctc, targets, wav_lens, target_lens)\n",
        "\n",
        "            self.per_metrics.append(\n",
        "                ids=ids,\n",
        "                predict=sequence,\n",
        "                target=targets,\n",
        "                predict_len=None,\n",
        "                target_len=target_lens,\n",
        "                ind2lab=self.label_encoder.decode_ndim,\n",
        "            )\n",
        "            self.mpd_metrics.append(\n",
        "                ids=ids,\n",
        "                predict=sequence,\n",
        "                canonical=canonicals,\n",
        "                perceived=perceiveds,\n",
        "                predict_len=None,\n",
        "                canonical_len=canonical_lens,\n",
        "                perceived_len=perceived_lens,\n",
        "                ind2lab=self.label_encoder.decode_ndim,\n",
        "            )\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def evaluate_batch(self, batch, stage):\n",
        "        \"\"\"Computations needed for validation/test batches\"\"\"\n",
        "        predictions = self.compute_forward(batch, stage=stage)\n",
        "        loss = self.compute_objectives(predictions, batch, stage=stage)\n",
        "        return loss.detach()\n",
        "\n",
        "    def on_stage_start(self, stage, epoch):\n",
        "        \"Gets called when a stage (either training, validation, test) starts.\"\n",
        "        self.ctc_metrics = self.hparams.ctc_stats()\n",
        "        if self.hparams.wav2vec2_specaug:\n",
        "            self.modules.wav2vec2.model.config.apply_spec_augment = True\n",
        "\n",
        "        if stage != sb.Stage.TRAIN:\n",
        "            self.modules.wav2vec2.model.config.apply_spec_augment = False\n",
        "            self.per_metrics = self.hparams.per_stats()\n",
        "            self.mpd_metrics = MpdStats()\n",
        "\n",
        "    def on_stage_end(self, stage, stage_loss, epoch):\n",
        "        \"\"\"Gets called at the end of a epoch.\"\"\"\n",
        "        stage_stats = {\"loss\": stage_loss}\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            self.train_loss = stage_loss\n",
        "        else:\n",
        "            per = self.per_metrics.summarize(\"error_rate\")\n",
        "            mpd_f1 = self.mpd_metrics.summarize(\"mpd_f1\")\n",
        "\n",
        "        if stage == sb.Stage.VALID:\n",
        "            old_lr_model, new_lr_model = self.hparams.lr_annealing_model(\n",
        "                stage_stats[\"loss\"]\n",
        "            )\n",
        "            old_lr_wav2vec2, new_lr_wav2vec2 = self.hparams.lr_annealing_wav2vec2(\n",
        "                stage_stats[\"loss\"]\n",
        "            )\n",
        "            sb.nnet.schedulers.update_learning_rate(\n",
        "                self.adam_optimizer, new_lr_model\n",
        "            )\n",
        "            sb.nnet.schedulers.update_learning_rate(\n",
        "                self.wav2vec_optimizer, new_lr_wav2vec2\n",
        "            )\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                stats_meta={\n",
        "                    \"epoch\": epoch,\n",
        "                    \"lr_model\": old_lr_model,\n",
        "                    \"lr_wav2vec2\": old_lr_wav2vec2,\n",
        "                },\n",
        "                train_stats={\"loss\": self.train_loss},\n",
        "                valid_stats={\n",
        "                    \"loss\": stage_loss,\n",
        "                    \"ctc_loss\": self.ctc_metrics.summarize(\"average\"),\n",
        "                    \"PER\": per,\n",
        "                    \"mpd_f1\": mpd_f1\n",
        "                },\n",
        "            )\n",
        "\n",
        "\n",
        "            # self.hparams.train_logger.log_stats(\n",
        "            #     stats_meta={\n",
        "            #         \"epoch\": epoch,\n",
        "            #         \"lr_adam\": self.adam_optimizer.param_groups[0][\"lr\"],\n",
        "            #         \"lr_wav2vec\": self.wav2vec_optimizer.param_groups[0][\"lr\"],\n",
        "            #     },\n",
        "            #     train_stats={\"loss\": self.train_loss},\n",
        "            #     valid_stats={\n",
        "            #         \"loss\": stage_loss,\n",
        "            #         \"ctc_loss\": self.ctc_metrics.summarize(\"average\"),\n",
        "            #         \"PER\": per,\n",
        "            #         \"mpd_f1\": mpd_f1\n",
        "            #     },\n",
        "            # )\n",
        "            self.checkpointer.save_and_keep_only(\n",
        "                meta={\"PER\": per, \"mpd_f1\": mpd_f1}, min_keys=[\"PER\"], max_keys=[\"mpd_f1\"]\n",
        "            )\n",
        "\n",
        "        if stage == sb.Stage.TEST:\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                stats_meta={\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
        "                test_stats={\"loss\": stage_loss, \"PER\": per, \"mpd_f1\": mpd_f1},\n",
        "            )\n",
        "            with open(self.hparams.wer_file, \"w\") as w:\n",
        "                w.write(\"CTC loss stats:\\n\")\n",
        "                self.ctc_metrics.write_stats(w)\n",
        "                w.write(\"\\nPER stats:\\n\")\n",
        "                self.per_metrics.write_stats(w)\n",
        "                print(\n",
        "                    \"CTC and PER stats written to file\",\n",
        "                    self.hparams.wer_file,\n",
        "                )\n",
        "            with open(self.hparams.mpd_file, \"w\") as m:\n",
        "                m.write(\"MPD results and stats:\\n\")\n",
        "                self.mpd_metrics.write_stats(m)\n",
        "                print(\n",
        "                    \"MPD results and stats written to file\",\n",
        "                    self.hparams.mpd_file,\n",
        "                )\n",
        "\n",
        "\n",
        "    def fit_batch(self, batch):\n",
        "        \"\"\"Fit one batch, override to do multiple updates.\n",
        "\n",
        "        The default implementation depends on a few methods being defined\n",
        "        with a particular behavior:\n",
        "\n",
        "        * ``compute_forward()``\n",
        "        * ``compute_objectives()``\n",
        "\n",
        "        Also depends on having optimizers passed at initialization.\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        batch : list of torch.Tensors\n",
        "            Batch of data to use for training. Default implementation assumes\n",
        "            this batch has two elements: inputs and targets.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        detached loss\n",
        "        \"\"\"\n",
        "        # Managing automatic mixed precision\n",
        "        if self.auto_mix_prec:\n",
        "\n",
        "            self.wav2vec_optimizer.zero_grad()\n",
        "            self.adam_optimizer.zero_grad()\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = self.compute_forward(batch, sb.Stage.TRAIN)\n",
        "                loss = self.compute_objectives(outputs, batch, sb.Stage.TRAIN)\n",
        "\n",
        "            self.scaler.scale(loss).backward()\n",
        "            self.scaler.unscale_(self.wav2vec_optimizer)\n",
        "            self.scaler.unscale_(self.adam_optimizer)\n",
        "\n",
        "            if self.check_gradients(loss):\n",
        "                self.scaler.step(self.wav2vec_optimizer)\n",
        "                self.scaler.step(self.adam_optimizer)\n",
        "\n",
        "            self.scaler.update()\n",
        "        else:\n",
        "            outputs = self.compute_forward(batch, sb.Stage.TRAIN)\n",
        "\n",
        "            loss = self.compute_objectives(outputs, batch, sb.Stage.TRAIN)\n",
        "            # normalize the loss by gradient_accumulation step\n",
        "            (loss / self.hparams.gradient_accumulation).backward()\n",
        "\n",
        "            if self.step % self.hparams.gradient_accumulation == 0:\n",
        "                # gradient clipping & early stop if loss is not fini\n",
        "                if self.check_gradients(loss):\n",
        "                    self.wav2vec_optimizer.step()\n",
        "                    self.adam_optimizer.step()\n",
        "\n",
        "                self.wav2vec_optimizer.zero_grad()\n",
        "                self.adam_optimizer.zero_grad()\n",
        "\n",
        "        return loss.detach().cpu()\n",
        "\n",
        "    def init_optimizers(self):\n",
        "        \"Initializes the wav2vec2 optimizer and model optimizer\"\n",
        "        self.wav2vec_optimizer = self.hparams.wav2vec_opt_class(\n",
        "            self.modules.wav2vec2.model.parameters()\n",
        "        )\n",
        "        self.adam_optimizer = self.hparams.adam_opt_class(\n",
        "            self.hparams.model.parameters()\n",
        "        )\n",
        "\n",
        "        if self.checkpointer is not None:\n",
        "            self.checkpointer.add_recoverable(\n",
        "                \"wav2vec_opt\", self.wav2vec_optimizer\n",
        "            )\n",
        "            self.checkpointer.add_recoverable(\"adam_opt\", self.adam_optimizer)\n",
        "\n",
        "    def on_fit_start(self):\n",
        "        \"\"\"Gets called at the beginning of ``fit()``, on multiple processes\n",
        "        if ``distributed_count > 0`` and backend is ddp.\n",
        "\n",
        "        Default implementation compiles the jit modules, initializes\n",
        "        optimizers, and loads the latest checkpoint to resume training.\n",
        "        \"\"\"\n",
        "        # Run this *after* starting all processes since jit modules cannot be\n",
        "        # pickled.\n",
        "        self._compile_jit()\n",
        "\n",
        "        # Wrap modules with parallel backend after jit\n",
        "        self._wrap_distributed()\n",
        "\n",
        "        # Initialize optimizers after parameters are configured\n",
        "        self.init_optimizers()\n",
        "\n",
        "        # Load latest checkpoint to resume training if interrupted\n",
        "        ## NOTE: make sure to use the \"best\" model to continual training\n",
        "        ## so we set the `min_key` argument\n",
        "        if self.checkpointer is not None:\n",
        "            self.checkpointer.recover_if_possible(\n",
        "                device=torch.device(self.device),\n",
        "                min_key=\"PER\"\n",
        "            )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nfd0QdzCeDuX"
      },
      "outputs": [],
      "source": [
        "def dataio_prep(hparams):\n",
        "    \"\"\"This function prepares the datasets to be used in the brain class.\n",
        "    It also defines the data processing pipeline through user-defined functions.\"\"\"\n",
        "    data_folder = hparams[\"data_folder_save\"]\n",
        "    # 1. Declarations:\n",
        "    train_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n",
        "        csv_path=hparams[\"train_annotation\"],\n",
        "        replacements={\"data_root\": data_folder},\n",
        "    )\n",
        "    if hparams[\"sorting\"] == \"ascending\":\n",
        "        # we sort training data to speed up training and get better results.\n",
        "        train_data = train_data.filtered_sorted(sort_key=\"duration\")\n",
        "        # when sorting do not shuffle in dataloader ! otherwise is pointless\n",
        "        hparams[\"train_dataloader_opts\"][\"shuffle\"] = False\n",
        "\n",
        "    elif hparams[\"sorting\"] == \"descending\":\n",
        "        train_data = train_data.filtered_sorted(\n",
        "            sort_key=\"duration\", reverse=True\n",
        "        )\n",
        "        # when sorting do not shuffle in dataloader ! otherwise is pointless\n",
        "        hparams[\"train_dataloader_opts\"][\"shuffle\"] = False\n",
        "\n",
        "    elif hparams[\"sorting\"] == \"random\":\n",
        "        pass\n",
        "\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            \"sorting must be random, ascending or descending\"\n",
        "        )\n",
        "\n",
        "    valid_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n",
        "        csv_path=hparams[\"valid_annotation\"],\n",
        "        replacements={\"data_root\": data_folder},\n",
        "    )\n",
        "    valid_data = valid_data.filtered_sorted(sort_key=\"duration\")\n",
        "\n",
        "    test_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n",
        "        csv_path=hparams[\"test_annotation\"],\n",
        "        replacements={\"data_root\": data_folder},\n",
        "    )\n",
        "    test_data = test_data.filtered_sorted(sort_key=\"duration\")\n",
        "\n",
        "    datasets = [train_data, valid_data, test_data]\n",
        "    label_encoder = sb.dataio.encoder.CTCTextEncoder()\n",
        "\n",
        "    # 2. Define audio pipeline:\n",
        "    @sb.utils.data_pipeline.takes(\"wav\")\n",
        "    @sb.utils.data_pipeline.provides(\"sig\")\n",
        "    def audio_pipeline(wav):\n",
        "        # sig = sb.dataio.dataio.read_audio(wav)\n",
        "        # # sample rate change to 16000, e,g, using librosa\n",
        "        # sig = torch.Tensor(librosa.core.load(wav, hparams[\"sample_rate\"])[0])\n",
        "        # Use wav2vec processor to do normalization\n",
        "        sig = hparams[\"wav2vec2\"].feature_extractor(\n",
        "            librosa.core.load(wav, sr=hparams[\"sample_rate\"])[0],\n",
        "            sampling_rate=hparams[\"sample_rate\"],\n",
        "        ).input_values[0]\n",
        "        sig = torch.Tensor(sig)\n",
        "        return sig\n",
        "\n",
        "    sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline)\n",
        "\n",
        "    # 3. Define text pipeline:\n",
        "    @sb.utils.data_pipeline.takes(\"perceived_train_target\")\n",
        "    @sb.utils.data_pipeline.provides(\n",
        "        \"phn_list_target\",\n",
        "        \"phn_encoded_list_target\",\n",
        "        \"phn_encoded_target\",\n",
        "    )\n",
        "    def text_pipeline_train(phn):\n",
        "        phn_list = phn.strip().split()\n",
        "        yield phn_list\n",
        "        phn_encoded_list = label_encoder.encode_sequence(phn_list)\n",
        "        yield phn_encoded_list\n",
        "        phn_encoded = torch.LongTensor(phn_encoded_list)\n",
        "        yield phn_encoded\n",
        "\n",
        "    @sb.utils.data_pipeline.takes(\"perceived_train_target\", \"canonical_aligned\", \"perceived_aligned\")\n",
        "    @sb.utils.data_pipeline.provides(\n",
        "        \"phn_list_target\",\n",
        "        \"phn_encoded_list_target\",\n",
        "        \"phn_encoded_target\",\n",
        "        \"phn_list_canonical\",\n",
        "        \"phn_encoded_list_canonical\",\n",
        "        \"phn_encoded_canonical\",\n",
        "        \"phn_list_perceived\",\n",
        "        \"phn_encoded_list_perceived\",\n",
        "        \"phn_encoded_perceived\",\n",
        "    )\n",
        "    def text_pipeline_test(target, canonical, perceived):\n",
        "        phn_list_target = target.strip().split()\n",
        "        yield phn_list_target\n",
        "        phn_encoded_list_target = label_encoder.encode_sequence(phn_list_target)\n",
        "        yield phn_encoded_list_target\n",
        "        phn_encoded_target = torch.LongTensor(phn_encoded_list_target)\n",
        "        yield phn_encoded_target\n",
        "        phn_list_canonical = canonical.strip().split()\n",
        "        yield phn_list_canonical\n",
        "        phn_encoded_list_canonical = label_encoder.encode_sequence(phn_list_canonical)\n",
        "        yield phn_encoded_list_canonical\n",
        "        phn_encoded_canonical = torch.LongTensor(phn_encoded_list_canonical)\n",
        "        yield phn_encoded_canonical\n",
        "        phn_list_perceived = perceived.strip().split()\n",
        "        yield phn_list_perceived\n",
        "        phn_encoded_list_perceived = label_encoder.encode_sequence(phn_list_perceived)\n",
        "        yield phn_encoded_list_perceived\n",
        "        phn_encoded_perceived = torch.LongTensor(phn_encoded_list_perceived)\n",
        "        yield phn_encoded_perceived\n",
        "\n",
        "    sb.dataio.dataset.add_dynamic_item([train_data], text_pipeline_train)\n",
        "    sb.dataio.dataset.add_dynamic_item([valid_data, test_data], text_pipeline_test)\n",
        "\n",
        "    # 3. Fit encoder:\n",
        "    # Load or compute the label encoder\n",
        "    lab_enc_file = os.path.join(hparams[\"save_folder\"], \"label_encoder.txt\")\n",
        "    special_labels = {\n",
        "        \"blank_label\": hparams[\"blank_index\"],\n",
        "    }\n",
        "    label_encoder.load_or_create(\n",
        "        path=lab_enc_file,\n",
        "        from_didatasets=[train_data],\n",
        "        output_key=\"phn_list_target\",\n",
        "        special_labels=special_labels,\n",
        "        sequence_input=True,\n",
        "    )\n",
        "\n",
        "    # 4. Set output:\n",
        "    sb.dataio.dataset.set_output_keys(\n",
        "        [train_data],\n",
        "        [\"id\", \"sig\", \"phn_encoded_target\"],\n",
        "    )\n",
        "    sb.dataio.dataset.set_output_keys(\n",
        "        [valid_data, test_data],\n",
        "        [\"id\", \"sig\", \"phn_encoded_target\", \"phn_encoded_canonical\", \"phn_encoded_perceived\"],\n",
        "    )\n",
        "\n",
        "    return train_data, valid_data, test_data, label_encoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVsbqzMyJBRL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c69f91ce-dd59-40a6-80f2-d6e678ebe83c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of HubertModel were not initialized from the model checkpoint at facebook/hubert-large-ls960-ft and are newly initialized: ['hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.lobes.models.huggingface_wav2vec - speechbrain.lobes.models.huggingface_wav2vec - wav2vec 2.0 feature extractor is frozen.\n",
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/hubert-base_ctc/\n",
            "speechbrain.dataio.encoder - Load called, but CTCTextEncoder is not empty. Loaded data will overwrite everything. This is normal if there is e.g. an unk label defined at init.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "hparams_file = '/content/drive/MyDrive/CS5647_Project/hparams/hubert_train.yaml'\n",
        "\n",
        "# Load hyperparameters file with command-line overrides\n",
        "with open(hparams_file) as fin:\n",
        "    hparams = load_hyperpyyaml(fin)\n",
        "\n",
        "\n",
        "# Create experiment directory\n",
        "sb.create_experiment_directory(\n",
        "    experiment_directory=hparams[\"output_folder\"],\n",
        "    hyperparams_to_save=hparams_file,\n",
        ")\n",
        "\n",
        "# Dataset IO prep: creating Dataset objects and proper encodings for phones\n",
        "train_data, valid_data, test_data, label_encoder = dataio_prep(hparams)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"NUMEXPR_MAX_THREADS\"] = \"12\""
      ],
      "metadata": {
        "id": "-b_FGnT7CaUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQHyc36_74th",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a37c9c98-69e2-4c00-ae11-01b7cf1e5d3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.core - Info: auto_mix_prec arg from hparam file is used\n",
            "speechbrain.core - 311.8M trainable parameters in ASR\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/hubert-base_ctc/save/CKPT+2023-11-22+12-00-55+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.epoch_loop - Going into epoch 36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/38 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "100%|██████████| 38/38 [00:43<00:00,  1.16s/it, train_loss=0.636]\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "100%|██████████| 19/19 [00:29<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 36, lr_model: 1.69e-04, lr_wav2vec2: 5.63e-06 - train loss: 6.36e-01 - valid loss: 4.79e-01, valid ctc_loss: 4.79e-01, valid PER: 16.03, valid mpd_f1: 3.86e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-19-21+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+12-00-55+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:27<00:00,  1.38it/s, train_loss=0.654]\n",
            "100%|██████████| 19/19 [00:13<00:00,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 37, lr_model: 1.69e-04, lr_wav2vec2: 5.63e-06 - train loss: 6.54e-01 - valid loss: 4.76e-01, valid ctc_loss: 4.75e-01, valid PER: 15.88, valid mpd_f1: 4.04e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-20-13+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-19-21+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:26<00:00,  1.43it/s, train_loss=0.662]\n",
            "100%|██████████| 19/19 [00:13<00:00,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 38, lr_model: 1.69e-04, lr_wav2vec2: 5.63e-06 - train loss: 6.62e-01 - valid loss: 4.72e-01, valid ctc_loss: 4.71e-01, valid PER: 15.43, valid mpd_f1: 4.08e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-21-03+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-20-13+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:26<00:00,  1.42it/s, train_loss=0.666]\n",
            "100%|██████████| 19/19 [00:13<00:00,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.nnet.schedulers - Changing lr from 0.00017 to 0.00013\n",
            "speechbrain.nnet.schedulers - Changing lr from 5.6e-06 to 4.2e-06\n",
            "speechbrain.utils.train_logger - epoch: 39, lr_model: 1.69e-04, lr_wav2vec2: 5.63e-06 - train loss: 6.66e-01 - valid loss: 4.71e-01, valid ctc_loss: 4.70e-01, valid PER: 15.14, valid mpd_f1: 3.94e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-21-55+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-21-03+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:26<00:00,  1.45it/s, train_loss=0.641]\n",
            "100%|██████████| 19/19 [00:12<00:00,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 40, lr_model: 1.27e-04, lr_wav2vec2: 4.22e-06 - train loss: 6.41e-01 - valid loss: 4.60e-01, valid ctc_loss: 4.59e-01, valid PER: 14.59, valid mpd_f1: 4.16e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-22-47+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-21-55+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:29<00:00,  1.29it/s, train_loss=0.644]\n",
            "100%|██████████| 19/19 [00:13<00:00,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 41, lr_model: 1.27e-04, lr_wav2vec2: 4.22e-06 - train loss: 6.44e-01 - valid loss: 4.55e-01, valid ctc_loss: 4.54e-01, valid PER: 14.68, valid mpd_f1: 4.22e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-23-42+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+11-41-56+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:27<00:00,  1.41it/s, train_loss=0.675]\n",
            "100%|██████████| 19/19 [00:13<00:00,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 42, lr_model: 1.27e-04, lr_wav2vec2: 4.22e-06 - train loss: 6.75e-01 - valid loss: 4.58e-01, valid ctc_loss: 4.57e-01, valid PER: 14.68, valid mpd_f1: 4.12e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-24-36+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:27<00:00,  1.41it/s, train_loss=0.65]\n",
            "100%|██████████| 19/19 [00:13<00:00,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 43, lr_model: 1.27e-04, lr_wav2vec2: 4.22e-06 - train loss: 6.50e-01 - valid loss: 4.53e-01, valid ctc_loss: 4.53e-01, valid PER: 14.35, valid mpd_f1: 4.18e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-25-27+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-22-47+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-24-36+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:26<00:00,  1.43it/s, train_loss=0.599]\n",
            "100%|██████████| 19/19 [00:13<00:00,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.nnet.schedulers - Changing lr from 0.00013 to 9.5e-05\n",
            "speechbrain.nnet.schedulers - Changing lr from 4.2e-06 to 3.2e-06\n",
            "speechbrain.utils.train_logger - epoch: 44, lr_model: 1.27e-04, lr_wav2vec2: 4.22e-06 - train loss: 5.99e-01 - valid loss: 4.54e-01, valid ctc_loss: 4.54e-01, valid PER: 14.18, valid mpd_f1: 4.17e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-26-21+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-25-27+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:27<00:00,  1.40it/s, train_loss=0.595]\n",
            "100%|██████████| 19/19 [00:13<00:00,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 45, lr_model: 9.49e-05, lr_wav2vec2: 3.16e-06 - train loss: 5.95e-01 - valid loss: 4.52e-01, valid ctc_loss: 4.51e-01, valid PER: 14.22, valid mpd_f1: 4.27e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-27-13+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-23-42+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:26<00:00,  1.41it/s, train_loss=0.603]\n",
            "100%|██████████| 19/19 [00:13<00:00,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 46, lr_model: 9.49e-05, lr_wav2vec2: 3.16e-06 - train loss: 6.03e-01 - valid loss: 4.52e-01, valid ctc_loss: 4.52e-01, valid PER: 14.35, valid mpd_f1: 4.22e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-28-07+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:26<00:00,  1.46it/s, train_loss=0.639]\n",
            "100%|██████████| 19/19 [00:13<00:00,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.nnet.schedulers - Changing lr from 9.5e-05 to 7.1e-05\n",
            "speechbrain.nnet.schedulers - Changing lr from 3.2e-06 to 2.4e-06\n",
            "speechbrain.utils.train_logger - epoch: 47, lr_model: 9.49e-05, lr_wav2vec2: 3.16e-06 - train loss: 6.39e-01 - valid loss: 4.53e-01, valid ctc_loss: 4.53e-01, valid PER: 14.05, valid mpd_f1: 4.19e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-28-59+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-28-07+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-26-21+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:26<00:00,  1.44it/s, train_loss=0.584]\n",
            "100%|██████████| 19/19 [00:12<00:00,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 48, lr_model: 7.12e-05, lr_wav2vec2: 2.37e-06 - train loss: 5.84e-01 - valid loss: 4.47e-01, valid ctc_loss: 4.47e-01, valid PER: 14.29, valid mpd_f1: 4.32e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-29-52+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-27-13+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:26<00:00,  1.45it/s, train_loss=0.569]\n",
            "100%|██████████| 19/19 [00:13<00:00,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 49, lr_model: 7.12e-05, lr_wav2vec2: 2.37e-06 - train loss: 5.69e-01 - valid loss: 4.47e-01, valid ctc_loss: 4.46e-01, valid PER: 14.02, valid mpd_f1: 4.28e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-30-48+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-28-59+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:26<00:00,  1.46it/s, train_loss=0.644]\n",
            "100%|██████████| 19/19 [00:12<00:00,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.nnet.schedulers - Changing lr from 7.1e-05 to 5.3e-05\n",
            "speechbrain.nnet.schedulers - Changing lr from 2.4e-06 to 1.8e-06\n",
            "speechbrain.utils.train_logger - epoch: 50, lr_model: 7.12e-05, lr_wav2vec2: 2.37e-06 - train loss: 6.44e-01 - valid loss: 4.48e-01, valid ctc_loss: 4.47e-01, valid PER: 13.92, valid mpd_f1: 4.28e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-31-38+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-22+13-30-48+00\n"
          ]
        }
      ],
      "source": [
        "# Trainer initialization\n",
        "asr_brain = ASR(\n",
        "    modules=hparams[\"modules\"],\n",
        "    hparams=hparams,\n",
        "    checkpointer=hparams[\"checkpointer\"],\n",
        "    run_opts = {\"device\": \"cuda\"}\n",
        ")\n",
        "asr_brain.label_encoder = label_encoder\n",
        "\n",
        "# Training/validation loop\n",
        "asr_brain.fit(\n",
        "    asr_brain.hparams.epoch_counter,\n",
        "    train_data,\n",
        "    valid_data,\n",
        "    train_loader_kwargs=hparams[\"train_dataloader_opts\"],\n",
        "    valid_loader_kwargs=hparams[\"valid_dataloader_opts\"],\n",
        "\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "asr_brain.evaluate(\n",
        "    test_data,\n",
        "    min_key=\"PER\",\n",
        "    test_loader_kwargs=hparams[\"test_dataloader_opts\"],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4tSMlfL7lCb",
        "outputId": "9dbae97e-3366-4f5c-a98e-da95809836e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/hubert-base_ctc/save/CKPT+2023-11-22+13-31-38+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [02:13<00:00,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - Epoch loaded: 50 - test loss: 5.70e-01, test PER: 15.38, test mpd_f1: 3.45e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CTC and PER stats written to file results/hubert-base_ctc//wer.txt\n",
            "MPD results and stats written to file results/hubert-base_ctc//mpd.txt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5704640717059375"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Njo4uu4Zl8cJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/checkpoint_latest.zip /content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edd0Y_StHhIw",
        "outputId": "638f3c5b-858c-45ad-b911-34af46f18c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/hubert_checkpoint/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/hubert_checkpoint/models--facebook--hubert-large-ls960-ft/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/hubert_checkpoint/models--facebook--hubert-large-ls960-ft/blobs/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/hubert_checkpoint/models--facebook--hubert-large-ls960-ft/blobs/36ebe8b7c1cc967b3059f0494ae8a1069dd67655 (deflated 35%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/hubert_checkpoint/models--facebook--hubert-large-ls960-ft/blobs/2cd99ac14fa1cde977c292af904d66aaa607120f (deflated 61%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/hubert_checkpoint/models--facebook--hubert-large-ls960-ft/blobs/9cf43abec3f0410ad6854afa4d376c69ccb364b48ddddfd25c4c5aa16398eab0 (deflated 41%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/hubert_checkpoint/models--facebook--hubert-large-ls960-ft/snapshots/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/hubert_checkpoint/models--facebook--hubert-large-ls960-ft/snapshots/ece5fabbf034c1073acae96d5401b25be96709d8/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/hubert_checkpoint/models--facebook--hubert-large-ls960-ft/snapshots/ece5fabbf034c1073acae96d5401b25be96709d8/preprocessor_config.json (deflated 35%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/hubert_checkpoint/models--facebook--hubert-large-ls960-ft/snapshots/ece5fabbf034c1073acae96d5401b25be96709d8/config.json (deflated 61%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/hubert_checkpoint/models--facebook--hubert-large-ls960-ft/snapshots/ece5fabbf034c1073acae96d5401b25be96709d8/pytorch_model.bin (deflated 41%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/hubert_checkpoint/models--facebook--hubert-large-ls960-ft/refs/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/hubert_checkpoint/models--facebook--hubert-large-ls960-ft/refs/main (stored 0%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/hubert_checkpoint/models--facebook--hubert-large-ls960-ft/.no_exist/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/hubert_checkpoint/models--facebook--hubert-large-ls960-ft/.no_exist/ece5fabbf034c1073acae96d5401b25be96709d8/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/hubert_checkpoint/models--facebook--hubert-large-ls960-ft/.no_exist/ece5fabbf034c1073acae96d5401b25be96709d8/model.safetensors (stored 0%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/hubert_checkpoint/models--facebook--hubert-large-ls960-ft/.no_exist/ece5fabbf034c1073acae96d5401b25be96709d8/model.safetensors.index.json (stored 0%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/hubert_checkpoint/.locks/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/hubert_checkpoint/.locks/models--facebook--hubert-large-ls960-ft/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/hubert_checkpoint/.locks/models--facebook--hubert-large-ls960-ft/36ebe8b7c1cc967b3059f0494ae8a1069dd67655.lock (stored 0%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/hubert_checkpoint/.locks/models--facebook--hubert-large-ls960-ft/2cd99ac14fa1cde977c292af904d66aaa607120f.lock (stored 0%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/hubert_checkpoint/.locks/models--facebook--hubert-large-ls960-ft/9cf43abec3f0410ad6854afa4d376c69ccb364b48ddddfd25c4c5aa16398eab0.lock (stored 0%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/label_encoder.txt (deflated 57%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/CKPT+2023-11-22+13-29-52+00/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/CKPT+2023-11-22+13-29-52+00/CKPT.yaml (deflated 6%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/CKPT+2023-11-22+13-29-52+00/model.ckpt (deflated 7%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/CKPT+2023-11-22+13-29-52+00/wav2vec2.ckpt (deflated 8%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/CKPT+2023-11-22+13-29-52+00/scheduler_model.ckpt (deflated 44%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/CKPT+2023-11-22+13-29-52+00/scheduler_wav2vec2.ckpt (deflated 45%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/CKPT+2023-11-22+13-29-52+00/counter.ckpt (stored 0%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/CKPT+2023-11-22+13-29-52+00/brain.ckpt (deflated 13%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/CKPT+2023-11-22+13-29-52+00/dataloader-TRAIN.ckpt (stored 0%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/CKPT+2023-11-22+13-29-52+00/wav2vec_opt.ckpt (deflated 9%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/CKPT+2023-11-22+13-29-52+00/adam_opt.ckpt (deflated 8%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/CKPT+2023-11-22+13-31-38+00/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/CKPT+2023-11-22+13-31-38+00/CKPT.yaml (deflated 6%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/CKPT+2023-11-22+13-31-38+00/model.ckpt (deflated 7%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/CKPT+2023-11-22+13-31-38+00/wav2vec2.ckpt (deflated 8%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/CKPT+2023-11-22+13-31-38+00/scheduler_model.ckpt (deflated 43%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/CKPT+2023-11-22+13-31-38+00/scheduler_wav2vec2.ckpt (deflated 44%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/CKPT+2023-11-22+13-31-38+00/counter.ckpt (stored 0%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/CKPT+2023-11-22+13-31-38+00/brain.ckpt (deflated 13%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/CKPT+2023-11-22+13-31-38+00/dataloader-TRAIN.ckpt (stored 0%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/CKPT+2023-11-22+13-31-38+00/wav2vec_opt.ckpt (deflated 9%)\n",
            "  adding: content/drive/MyDrive/CS5647_Project/results/hubert-base_ctc/save/CKPT+2023-11-22+13-31-38+00/adam_opt.ckpt (deflated 8%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nh60DUuPViI5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}