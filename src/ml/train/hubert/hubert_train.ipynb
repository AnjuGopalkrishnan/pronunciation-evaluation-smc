{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing required packages"
      ],
      "metadata": {
        "id": "kJErFaz_Eib4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kWkjs_8PHcBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f98256a-8498-4366-f064-6a08b54a15fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting speechbrain\n",
            "  Downloading speechbrain-0.5.16-py3-none-any.whl (630 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/630.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/630.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m630.6/630.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperpyyaml (from speechbrain)\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from speechbrain) (23.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.11.3)\n",
            "Collecting sentencepiece (from speechbrain)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from speechbrain) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from speechbrain) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from speechbrain) (4.66.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from speechbrain) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain) (6.0.1)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml-0.18.5-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->speechbrain) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->speechbrain) (1.3.0)\n",
            "Installing collected packages: sentencepiece, ruamel.yaml.clib, ruamel.yaml, hyperpyyaml, speechbrain\n",
            "Successfully installed hyperpyyaml-1.2.2 ruamel.yaml-0.18.5 ruamel.yaml.clib-0.2.8 sentencepiece-0.1.99 speechbrain-0.5.16\n",
            "Collecting textgrid\n",
            "  Downloading TextGrid-1.5-py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.7)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Installing collected packages: textgrid\n",
            "Successfully installed textgrid-1.5\n"
          ]
        }
      ],
      "source": [
        "!pip install speechbrain\n",
        "!pip install textgrid transformers librosa"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing requried modules"
      ],
      "metadata": {
        "collapsed": false,
        "id": "u8fI9Iibo8S9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import logging\n",
        "import speechbrain as sb\n",
        "from hyperpyyaml import load_hyperpyyaml\n",
        "import librosa\n",
        "import csv\n",
        "from google.colab import drive, files\n",
        "from io import StringIO\n",
        "from speechbrain.utils.metric_stats import ErrorRateStats"
      ],
      "metadata": {
        "id": "WN7jVI96o8S9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mounting google drive"
      ],
      "metadata": {
        "collapsed": false,
        "id": "lP25vzN-o8S-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kiA9SjWIHOx5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f574fe25-00a3-49db-be4a-e0eb8eb179c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Constants & Importing Eval metric file"
      ],
      "metadata": {
        "collapsed": false,
        "id": "SD2Flqbio8S_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sikO-MV-Iv0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61bca60f-bf83-4f6d-8189-da8aa510cccc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Working Directory after change: /content/drive/MyDrive/CS5647_Project\n"
          ]
        }
      ],
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "folder_path = '/content/drive/MyDrive/CS5647_Project'\n",
        "os.chdir(folder_path)\n",
        "current_directory = os.getcwd()\n",
        "print(\"Current Working Directory after change:\", current_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZQkBQKicOBmT"
      },
      "outputs": [],
      "source": [
        "from mpd_eval_v3 import MpdStats"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the speech brain object"
      ],
      "metadata": {
        "collapsed": false,
        "id": "JlwgKAoTo8TA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "P3meQIqYI1tr"
      },
      "outputs": [],
      "source": [
        "def make_attn_mask(wavs, wav_lens):\n",
        "    \"\"\"\n",
        "    wav_lens: relative lengths(i.e. 0-1) of a batch. shape: (bs, )\n",
        "    return a tensor of shape (bs, seq_len), representing mask on allowed positions.\n",
        "            1 for regular tokens, 0 for padded tokens\n",
        "    \"\"\"\n",
        "    abs_lens = (wav_lens*wavs.shape[1]).long()\n",
        "    attn_mask = wavs.new(wavs.shape).zero_().long()\n",
        "    for i in range(len(abs_lens)):\n",
        "        attn_mask[i, :abs_lens[i]] = 1\n",
        "    return attn_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "MRjl6kGqI7Lr"
      },
      "outputs": [],
      "source": [
        "class ASR(sb.Brain):\n",
        "    # Inference code\n",
        "        #Testing for one single audio file\n",
        "    def compute_forward_evaluate(self, batch, stage):\n",
        "        \"Given an input batch it computes the phoneme probabilities.\"\n",
        "        batch = batch.to(self.device)\n",
        "        wavs = batch\n",
        "\n",
        "        #creating a dummy wav_lens with shape of [batch,1] with 1\n",
        "        wav_lens = torch.ones((1,1)).to(self.device)\n",
        "\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            if hasattr(self.hparams, \"augmentation\"):\n",
        "                wavs = self.hparams.augmentation(wavs, wav_lens)\n",
        "\n",
        "        attn_mask = None\n",
        "        feats = self.modules.wav2vec2(wavs)\n",
        "\n",
        "        x = self.modules.enc(feats)\n",
        "\n",
        "        # output layer for ctc log-probabilities\n",
        "        logits = self.modules.ctc_lin(x)\n",
        "        p_ctc = self.hparams.log_softmax(logits)\n",
        "        # Note: sb.decoders.ctc_greedy_decode will also remove padded tokens\n",
        "        # that is, it return a list of list with different lengths\n",
        "        sequence = sb.decoders.ctc_greedy_decode(\n",
        "            p_ctc, wav_lens, blank_id=self.hparams.blank_index\n",
        "        )\n",
        "        transcriptions = [\" \".join(self.label_encoder.decode_ndim(s)) for s in sequence]\n",
        "        return transcriptions, sequence\n",
        "\n",
        "    def prepare_test_audio_for_inference(self, test_audio_path):\n",
        "        # Use wav2vec processor to do normalization\n",
        "        audio_signal, _ = librosa.core.load(test_audio_path, sr=self.hparams.sample_rate)\n",
        "        sig = self.hparams.wav2vec2.feature_extractor(\n",
        "            audio_signal,\n",
        "            sampling_rate=self.hparams.sample_rate,\n",
        "        ).input_values #since its only 1 file not taking [0]\n",
        "\n",
        "        sig = torch.Tensor(sig)\n",
        "        return sig\n",
        "\n",
        "    def get_predicted_phonemes_for_test_audio(self, test_audio_path):\n",
        "        print(f\"Using librosa to load the audio\")\n",
        "        batch = self.prepare_test_audio_for_inference(test_audio_path)\n",
        "        print(f\"Loading the best model & setting to eval mode\")\n",
        "        self.on_evaluate_start(min_key=\"PER\") # We call the on_evaluate_start that will load the best model\n",
        "        self.modules.eval() # We set the model to eval mode (remove dropout etc)\n",
        "        self.modules.wav2vec2.model.config.apply_spec_augment = False  # make sure no spec aug applied on wav2vec2\n",
        "\n",
        "        with torch.no_grad():\n",
        "          print(\"Making predictions from the best model\")\n",
        "          preds, seq = self.compute_forward_evaluate(batch, stage=sb.Stage.TEST)\n",
        "          print(\"Got the predictions\")\n",
        "        return preds, seq\n",
        "\n",
        "    def evaluate_test_audio(self, test_audio_path, canonical_phonemes):\n",
        "        predicted_phonemes, predicted_sequence = self.get_predicted_phonemes_for_test_audio(test_audio_path)\n",
        "        predicted_phonemes = predicted_phonemes.split()\n",
        "        predicted_sequence_without_sil = [[]]\n",
        "\n",
        "        # Ensure that we remove the sils\n",
        "        for pred_phoneme, pred_seq in zip(predicted_phonemes, predicted_sequence[0]):\n",
        "            if pred_phoneme != \"sil\":\n",
        "                predicted_sequence_without_sil[0].append(pred_seq)\n",
        "\n",
        "\n",
        "        print(\"Converting canonical to appropriate format for getting error\")\n",
        "        phn_list_canonical = canonical_phonemes.strip().split()\n",
        "        phn_list_canonical_without_sil = list(filter(lambda phn: phn != \"sil\", phn_list_canonical))\n",
        "        phn_encoded_list_canonical = [self.label_encoder.encode_sequence(phn_list_canonical_without_sil)]\n",
        "        canonicals = torch.LongTensor(phn_encoded_list_canonical)\n",
        "        canonical_lens = torch.ones((1,1))\n",
        "\n",
        "        print(\"Getting the error stats\")\n",
        "        error_metrics = ErrorRateStats()\n",
        "        error_metrics.append(\n",
        "                        ids=[test_audio_path],\n",
        "                        predict=predicted_sequence_without_sil,\n",
        "                        target=canonicals,\n",
        "                        predict_len=None,\n",
        "                        target_len=canonical_lens,\n",
        "                        ind2lab=self.label_encoder.decode_ndim,\n",
        "                    )\n",
        "        stats = error_metrics.summarize()\n",
        "        # get score (100 - WER)\n",
        "        score = 100 - stats[\"WER\"]\n",
        "        print(f\"Calculated the score to be: {score}\")\n",
        "        print(\"Now capturing the stats sysout in a variable\")\n",
        "        # get the errors\n",
        "        # Redirect sys.stdout to capture the output\n",
        "        original_stdout = sys.stdout\n",
        "        sys.stdout = StringIO()\n",
        "\n",
        "        # Call write_stats\n",
        "        error_metrics.write_stats(None)\n",
        "\n",
        "        # Get the content of the buffer\n",
        "        stats_string = sys.stdout.getvalue()\n",
        "\n",
        "        # Reset sys.stdout\n",
        "        sys.stdout = original_stdout\n",
        "        print(\"Extracting stats from stdout\")\n",
        "        return predicted_phonemes, score, self.extract_stats_from_wer_stats_string(stats_string)\n",
        "\n",
        "    def extract_stats_from_wer_stats_string(self, stats_string):\n",
        "        lines = stats_string.split('\\n')\n",
        "        lines = [line.strip() for line in lines]\n",
        "\n",
        "        # Find the start and end of the ALIGNMENTS section\n",
        "        alignments_start = lines.index(\"ALIGNMENTS\")\n",
        "        alignments_end = lines.index(\"================================================================================\", alignments_start+1)\n",
        "        alignments_lines = lines[alignments_end+1:]\n",
        "\n",
        "        # Process alignments\n",
        "        canonical = [phn.strip() for phn in alignments_lines[1].split(';')]\n",
        "        operator = [op.strip() for op in alignments_lines[2].split(';')]\n",
        "        predicted = [phn.strip() for phn in  alignments_lines[3].split(';')]\n",
        "\n",
        "        # Initialize error categories\n",
        "        errors = {\n",
        "            \"deletions\": {\"canonical\": [], \"predicted\": []},\n",
        "            \"insertions\": {\"canonical\": [], \"predicted\": []},\n",
        "            \"substitutions\": {\"canonical\": [], \"predicted\": []},\n",
        "            \"canonical\": canonical,\n",
        "            \"predicted\": predicted\n",
        "        }\n",
        "\n",
        "        for i, item in enumerate(zip(canonical, operator, predicted)):\n",
        "            canonical_phn, op, predicted_phn = item\n",
        "            if op == \"I\":\n",
        "                errors[\"insertions\"][\"canonical\"].append((i, canonical_phn))\n",
        "                errors[\"insertions\"][\"predicted\"].append((i, predicted_phn))\n",
        "            elif op == \"S\":\n",
        "                errors[\"substitutions\"][\"canonical\"].append((i, canonical_phn))\n",
        "                errors[\"substitutions\"][\"predicted\"].append((i, predicted_phn))\n",
        "            elif op == \"D\":\n",
        "                errors[\"deletions\"][\"canonical\"].append((i, canonical_phn))\n",
        "                errors[\"deletions\"][\"predicted\"].append((i, predicted_phn))\n",
        "\n",
        "        return errors\n",
        "\n",
        "    #Testing for one single audio file\n",
        "    def compute_forward_evaluate(self, batch, stage):\n",
        "        \"Given an input batch it computes the phoneme probabilities.\"\n",
        "        batch = batch.to(self.device)\n",
        "        wavs = batch\n",
        "\n",
        "        #creating a dummy wav_lens with shape of [batch,1] with 1\n",
        "        wav_lens = torch.ones((1,1)).to(self.device)\n",
        "\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            if hasattr(self.hparams, \"augmentation\"):\n",
        "                wavs = self.hparams.augmentation(wavs, wav_lens)\n",
        "\n",
        "        attn_mask = None\n",
        "        feats = self.modules.wav2vec2(wavs)\n",
        "\n",
        "        x = self.modules.enc(feats)\n",
        "\n",
        "        # output layer for ctc log-probabilities\n",
        "        logits = self.modules.ctc_lin(x)\n",
        "        p_ctc = self.hparams.log_softmax(logits)\n",
        "        # Note: sb.decoders.ctc_greedy_decode will also remove padded tokens\n",
        "        # that is, it return a list of list with different lengths\n",
        "        sequence = sb.decoders.ctc_greedy_decode(\n",
        "            p_ctc, wav_lens, blank_id=self.hparams.blank_index\n",
        "        )\n",
        "        transcriptions = [\" \".join(self.label_encoder.decode_ndim(s)) for s in sequence]\n",
        "        return transcriptions, sequence\n",
        "\n",
        "    def prepare_test_audio_for_inference(self, test_audio_path):\n",
        "        # Use wav2vec processor to do normalization\n",
        "        audio_signal, _ = librosa.core.load(test_audio_path, sr=self.hparams.sample_rate)\n",
        "        sig = self.hparams.wav2vec2.feature_extractor(\n",
        "            audio_signal,\n",
        "            sampling_rate=self.hparams.sample_rate,\n",
        "        ).input_values #since its only 1 file not taking [0]\n",
        "\n",
        "        sig = torch.Tensor(sig)\n",
        "        return sig\n",
        "\n",
        "    def get_predicted_phonemes_for_test_audio(self, test_audio_path):\n",
        "        print(f\"Using librosa to load the audio\")\n",
        "        batch = self.prepare_test_audio_for_inference(test_audio_path)\n",
        "        print(f\"Loading the best model & setting to eval mode\")\n",
        "        self.on_evaluate_start(min_key=\"PER\") # We call the on_evaluate_start that will load the best model\n",
        "        self.modules.eval() # We set the model to eval mode (remove dropout etc)\n",
        "        self.modules.wav2vec2.model.config.apply_spec_augment = False  # make sure no spec aug applied on wav2vec2\n",
        "\n",
        "        with torch.no_grad():\n",
        "          print(\"Making predictions from the best model\")\n",
        "          preds, seq = self.compute_forward_evaluate(batch, stage=sb.Stage.TEST)\n",
        "          print(\"Got the predictions\")\n",
        "        return preds, seq\n",
        "\n",
        "    def evaluate_test_audio(self, test_audio_path, canonical_phonemes):\n",
        "        predicted_phonemes, predicted_sequence = self.get_predicted_phonemes_for_test_audio(test_audio_path)\n",
        "\n",
        "        print(\"Converting canonical to appropriate format for getting error\")\n",
        "        phn_list_canonical = canonical_phonemes.strip().split()\n",
        "        phn_encoded_list_canonical = [self.label_encoder.encode_sequence(phn_list_canonical)]\n",
        "        canonicals = torch.LongTensor(phn_encoded_list_canonical)\n",
        "        canonical_lens = torch.ones((1,1))\n",
        "\n",
        "        print(\"Getting the error stats\")\n",
        "        error_metrics = ErrorRateStats()\n",
        "        error_metrics.append(\n",
        "                        ids=[test_audio_path],\n",
        "                        predict=predicted_sequence,\n",
        "                        target=canonicals,\n",
        "                        predict_len=None,\n",
        "                        target_len=canonical_lens,\n",
        "                        ind2lab=self.label_encoder.decode_ndim,\n",
        "                    )\n",
        "        stats = error_metrics.summarize()\n",
        "        # get score (100 - WER)\n",
        "        score = 100 - stats[\"WER\"]\n",
        "        print(f\"Calculated the score to be: {score}\")\n",
        "        print(\"Now capturing the stats sysout in a variable\")\n",
        "        # get the errors\n",
        "        # Redirect sys.stdout to capture the output\n",
        "        original_stdout = sys.stdout\n",
        "        sys.stdout = StringIO()\n",
        "\n",
        "        # Call write_stats\n",
        "        error_metrics.write_stats(None)\n",
        "\n",
        "        # Get the content of the buffer\n",
        "        stats_string = sys.stdout.getvalue()\n",
        "\n",
        "        # Reset sys.stdout\n",
        "        sys.stdout = original_stdout\n",
        "        print(\"Extracting stats from stdout\")\n",
        "        return predicted_phonemes, score, self.extract_stats_from_wer_stats_string(stats_string)\n",
        "\n",
        "    def extract_stats_from_wer_stats_string(self, stats_string):\n",
        "        lines = stats_string.split('\\n')\n",
        "        lines = [line.strip() for line in lines]\n",
        "\n",
        "        # Find the start and end of the ALIGNMENTS section\n",
        "        alignments_start = lines.index(\"ALIGNMENTS\")\n",
        "        alignments_end = lines.index(\"================================================================================\", alignments_start+1)\n",
        "        alignments_lines = lines[alignments_end+1:]\n",
        "\n",
        "        # Process alignments\n",
        "        canonical = [phn.strip() for phn in alignments_lines[1].split(';')]\n",
        "        operator = [op.strip() for op in alignments_lines[2].split(';')]\n",
        "        predicted = [phn.strip() for phn in  alignments_lines[3].split(';')]\n",
        "\n",
        "        # Initialize error categories\n",
        "        errors = {\n",
        "            \"deletions\": {\"canonical\": [], \"predicted\": []},\n",
        "            \"insertions\": {\"canonical\": [], \"predicted\": []},\n",
        "            \"substitutions\": {\"canonical\": [], \"predicted\": []},\n",
        "            \"canonical\": canonical,\n",
        "            \"predicted\": predicted\n",
        "        }\n",
        "\n",
        "        for i, item in enumerate(zip(canonical, operator, predicted)):\n",
        "            canonical_phn, op, predicted_phn = item\n",
        "            if op == \"I\":\n",
        "                errors[\"insertions\"][\"canonical\"].append((i, canonical_phn))\n",
        "                errors[\"insertions\"][\"predicted\"].append((i, predicted_phn))\n",
        "            elif op == \"S\":\n",
        "                errors[\"substitutions\"][\"canonical\"].append((i, canonical_phn))\n",
        "                errors[\"substitutions\"][\"predicted\"].append((i, predicted_phn))\n",
        "            elif op == \"D\":\n",
        "                errors[\"deletions\"][\"canonical\"].append((i, canonical_phn))\n",
        "                errors[\"deletions\"][\"predicted\"].append((i, predicted_phn))\n",
        "\n",
        "        return errors\n",
        "\n",
        "    # Training code\n",
        "    def _compile_jit(self):\n",
        "        for module in self.modules:\n",
        "            if hasattr(module, \"_compile_jit\"):\n",
        "                module._compile_jit()\n",
        "\n",
        "    def compute_forward(self, batch, stage):\n",
        "        \"Given an input batch it computes the phoneme probabilities.\"\n",
        "        batch = batch.to(self.device)\n",
        "        wavs, wav_lens = batch.sig\n",
        "        # phns_bos, _ = batch.phn_encoded_bos\n",
        "\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            if hasattr(self.hparams, \"augmentation\"):\n",
        "                wavs = self.hparams.augmentation(wavs, wav_lens)\n",
        "\n",
        "        # some wav2vec models (e.g. large-lv60) needs attention_mask\n",
        "        # if self.modules.wav2vec2.feature_extractor.return_attention_mask:\n",
        "        #     attn_mask = make_attn_mask(wavs, wav_lens)\n",
        "        #     feats = self.modules.wav2vec2(wavs, attention_mask=attn_mask)\n",
        "        # else:\n",
        "        #     attn_mask = None\n",
        "        #     feats = self.modules.wav2vec2(wavs)\n",
        "        feats = self.modules.wav2vec2(wavs)\n",
        "        x = self.modules.enc(feats)\n",
        "\n",
        "        # output layer for ctc log-probabilities\n",
        "        logits = self.modules.ctc_lin(x)\n",
        "        p_ctc = self.hparams.log_softmax(logits)\n",
        "\n",
        "        return p_ctc, wav_lens\n",
        "\n",
        "    def compute_objectives(self, predictions, batch, stage):\n",
        "        \"Given the network predictions and targets computed the NLL loss.\"\n",
        "\n",
        "        p_ctc, wav_lens = predictions\n",
        "\n",
        "        ids = batch.id\n",
        "        targets, target_lens = batch.phn_encoded_target\n",
        "        if stage != sb.Stage.TRAIN:\n",
        "            canonicals, canonical_lens = batch.phn_encoded_canonical\n",
        "            perceiveds, perceived_lens = batch.phn_encoded_perceived\n",
        "\n",
        "        loss_ctc = self.hparams.ctc_cost(p_ctc, targets, wav_lens, target_lens)\n",
        "        loss = loss_ctc\n",
        "\n",
        "        # Record losses for posterity\n",
        "        if stage != sb.Stage.TRAIN:\n",
        "            # Note: sb.decoders.ctc_greedy_decode will also remove padded tokens\n",
        "            # that is, it return a list of list with different lengths\n",
        "            sequence = sb.decoders.ctc_greedy_decode(\n",
        "                p_ctc, wav_lens, blank_id=self.hparams.blank_index\n",
        "            )\n",
        "            self.ctc_metrics.append(ids, p_ctc, targets, wav_lens, target_lens)\n",
        "\n",
        "            self.per_metrics.append(\n",
        "                ids=ids,\n",
        "                predict=sequence,\n",
        "                target=targets,\n",
        "                predict_len=None,\n",
        "                target_len=target_lens,\n",
        "                ind2lab=self.label_encoder.decode_ndim,\n",
        "            )\n",
        "            self.mpd_metrics.append(\n",
        "                ids=ids,\n",
        "                predict=sequence,\n",
        "                canonical=canonicals,\n",
        "                perceived=perceiveds,\n",
        "                predict_len=None,\n",
        "                canonical_len=canonical_lens,\n",
        "                perceived_len=perceived_lens,\n",
        "                ind2lab=self.label_encoder.decode_ndim,\n",
        "            )\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def evaluate_batch(self, batch, stage):\n",
        "        \"\"\"Computations needed for validation/test batches\"\"\"\n",
        "        predictions = self.compute_forward(batch, stage=stage)\n",
        "        loss = self.compute_objectives(predictions, batch, stage=stage)\n",
        "        return loss.detach()\n",
        "\n",
        "    def on_stage_start(self, stage, epoch):\n",
        "        \"Gets called when a stage (either training, validation, test) starts.\"\n",
        "        self.ctc_metrics = self.hparams.ctc_stats()\n",
        "        if self.hparams.wav2vec2_specaug:\n",
        "            self.modules.wav2vec2.model.config.apply_spec_augment = True\n",
        "\n",
        "        if stage != sb.Stage.TRAIN:\n",
        "            self.modules.wav2vec2.model.config.apply_spec_augment = False\n",
        "            self.per_metrics = self.hparams.per_stats()\n",
        "            self.mpd_metrics = MpdStats()\n",
        "\n",
        "    def on_stage_end(self, stage, stage_loss, epoch):\n",
        "        \"\"\"Gets called at the end of a epoch.\"\"\"\n",
        "        stage_stats = {\"loss\": stage_loss}\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            self.train_loss = stage_loss\n",
        "        else:\n",
        "            per = self.per_metrics.summarize(\"error_rate\")\n",
        "            mpd_f1 = self.mpd_metrics.summarize(\"mpd_f1\")\n",
        "\n",
        "        if stage == sb.Stage.VALID:\n",
        "            old_lr_model, new_lr_model = self.hparams.lr_annealing_model(\n",
        "                stage_stats[\"loss\"]\n",
        "            )\n",
        "            old_lr_wav2vec2, new_lr_wav2vec2 = self.hparams.lr_annealing_wav2vec2(\n",
        "                stage_stats[\"loss\"]\n",
        "            )\n",
        "            sb.nnet.schedulers.update_learning_rate(\n",
        "                self.adam_optimizer, new_lr_model\n",
        "            )\n",
        "            sb.nnet.schedulers.update_learning_rate(\n",
        "                self.wav2vec_optimizer, new_lr_wav2vec2\n",
        "            )\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                stats_meta={\n",
        "                    \"epoch\": epoch,\n",
        "                    \"lr_model\": old_lr_model,\n",
        "                    \"lr_wav2vec2\": old_lr_wav2vec2,\n",
        "                },\n",
        "                train_stats={\"loss\": self.train_loss},\n",
        "                valid_stats={\n",
        "                    \"loss\": stage_loss,\n",
        "                    \"ctc_loss\": self.ctc_metrics.summarize(\"average\"),\n",
        "                    \"PER\": per,\n",
        "                    \"mpd_f1\": mpd_f1\n",
        "                },\n",
        "            )\n",
        "\n",
        "\n",
        "            # self.hparams.train_logger.log_stats(\n",
        "            #     stats_meta={\n",
        "            #         \"epoch\": epoch,\n",
        "            #         \"lr_adam\": self.adam_optimizer.param_groups[0][\"lr\"],\n",
        "            #         \"lr_wav2vec\": self.wav2vec_optimizer.param_groups[0][\"lr\"],\n",
        "            #     },\n",
        "            #     train_stats={\"loss\": self.train_loss},\n",
        "            #     valid_stats={\n",
        "            #         \"loss\": stage_loss,\n",
        "            #         \"ctc_loss\": self.ctc_metrics.summarize(\"average\"),\n",
        "            #         \"PER\": per,\n",
        "            #         \"mpd_f1\": mpd_f1\n",
        "            #     },\n",
        "            # )\n",
        "            self.checkpointer.save_and_keep_only(\n",
        "                meta={\"PER\": per, \"mpd_f1\": mpd_f1}, min_keys=[\"PER\"], max_keys=[\"mpd_f1\"]\n",
        "            )\n",
        "\n",
        "        if stage == sb.Stage.TEST:\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                stats_meta={\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
        "                test_stats={\"loss\": stage_loss, \"PER\": per, \"mpd_f1\": mpd_f1},\n",
        "            )\n",
        "            with open(self.hparams.wer_file, \"w\") as w:\n",
        "                w.write(\"CTC loss stats:\\n\")\n",
        "                self.ctc_metrics.write_stats(w)\n",
        "                w.write(\"\\nPER stats:\\n\")\n",
        "                self.per_metrics.write_stats(w)\n",
        "                print(\n",
        "                    \"CTC and PER stats written to file\",\n",
        "                    self.hparams.wer_file,\n",
        "                )\n",
        "            with open(self.hparams.mpd_file, \"w\") as m:\n",
        "                m.write(\"MPD results and stats:\\n\")\n",
        "                self.mpd_metrics.write_stats(m)\n",
        "                print(\n",
        "                    \"MPD results and stats written to file\",\n",
        "                    self.hparams.mpd_file,\n",
        "                )\n",
        "\n",
        "\n",
        "    def fit_batch(self, batch):\n",
        "        \"\"\"Fit one batch, override to do multiple updates.\n",
        "\n",
        "        The default implementation depends on a few methods being defined\n",
        "        with a particular behavior:\n",
        "\n",
        "        * ``compute_forward()``\n",
        "        * ``compute_objectives()``\n",
        "\n",
        "        Also depends on having optimizers passed at initialization.\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        batch : list of torch.Tensors\n",
        "            Batch of data to use for training. Default implementation assumes\n",
        "            this batch has two elements: inputs and targets.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        detached loss\n",
        "        \"\"\"\n",
        "        # Managing automatic mixed precision\n",
        "        if self.auto_mix_prec:\n",
        "\n",
        "            self.wav2vec_optimizer.zero_grad()\n",
        "            self.adam_optimizer.zero_grad()\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = self.compute_forward(batch, sb.Stage.TRAIN)\n",
        "                loss = self.compute_objectives(outputs, batch, sb.Stage.TRAIN)\n",
        "\n",
        "            self.scaler.scale(loss).backward()\n",
        "            self.scaler.unscale_(self.wav2vec_optimizer)\n",
        "            self.scaler.unscale_(self.adam_optimizer)\n",
        "\n",
        "            if self.check_gradients(loss):\n",
        "                self.scaler.step(self.wav2vec_optimizer)\n",
        "                self.scaler.step(self.adam_optimizer)\n",
        "\n",
        "            self.scaler.update()\n",
        "        else:\n",
        "            outputs = self.compute_forward(batch, sb.Stage.TRAIN)\n",
        "\n",
        "            loss = self.compute_objectives(outputs, batch, sb.Stage.TRAIN)\n",
        "            # normalize the loss by gradient_accumulation step\n",
        "            (loss / self.hparams.gradient_accumulation).backward()\n",
        "\n",
        "            if self.step % self.hparams.gradient_accumulation == 0:\n",
        "                # gradient clipping & early stop if loss is not fini\n",
        "                if self.check_gradients(loss):\n",
        "                    self.wav2vec_optimizer.step()\n",
        "                    self.adam_optimizer.step()\n",
        "\n",
        "                self.wav2vec_optimizer.zero_grad()\n",
        "                self.adam_optimizer.zero_grad()\n",
        "\n",
        "        return loss.detach().cpu()\n",
        "\n",
        "    def init_optimizers(self):\n",
        "        \"Initializes the wav2vec2 optimizer and model optimizer\"\n",
        "        self.wav2vec_optimizer = self.hparams.wav2vec_opt_class(\n",
        "            self.modules.wav2vec2.model.parameters()\n",
        "        )\n",
        "        self.adam_optimizer = self.hparams.adam_opt_class(\n",
        "            self.hparams.model.parameters()\n",
        "        )\n",
        "\n",
        "        if self.checkpointer is not None:\n",
        "            self.checkpointer.add_recoverable(\n",
        "                \"wav2vec_opt\", self.wav2vec_optimizer\n",
        "            )\n",
        "            self.checkpointer.add_recoverable(\"adam_opt\", self.adam_optimizer)\n",
        "\n",
        "    def on_fit_start(self):\n",
        "        \"\"\"Gets called at the beginning of ``fit()``, on multiple processes\n",
        "        if ``distributed_count > 0`` and backend is ddp.\n",
        "\n",
        "        Default implementation compiles the jit modules, initializes\n",
        "        optimizers, and loads the latest checkpoint to resume training.\n",
        "        \"\"\"\n",
        "        # Run this *after* starting all processes since jit modules cannot be\n",
        "        # pickled.\n",
        "        self._compile_jit()\n",
        "\n",
        "        # Wrap modules with parallel backend after jit\n",
        "        self._wrap_distributed()\n",
        "\n",
        "        # Initialize optimizers after parameters are configured\n",
        "        self.init_optimizers()\n",
        "\n",
        "        # Load latest checkpoint to resume training if interrupted\n",
        "        ## NOTE: make sure to use the \"best\" model to continual training\n",
        "        ## so we set the `min_key` argument\n",
        "        if self.checkpointer is not None:\n",
        "            self.checkpointer.recover_if_possible(\n",
        "                device=torch.device(self.device),\n",
        "                min_key=\"PER\"\n",
        "            )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Speech Brain Data preparation"
      ],
      "metadata": {
        "collapsed": false,
        "id": "IwPaUWvjo8TC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Nfd0QdzCeDuX"
      },
      "outputs": [],
      "source": [
        "def dataio_prep(hparams):\n",
        "    \"\"\"This function prepares the datasets to be used in the brain class.\n",
        "    It also defines the data processing pipeline through user-defined functions.\"\"\"\n",
        "    data_folder = hparams[\"data_folder_save\"]\n",
        "    # 1. Declarations:\n",
        "    train_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n",
        "        csv_path=hparams[\"train_annotation\"],\n",
        "        replacements={\"data_root\": data_folder},\n",
        "    )\n",
        "    if hparams[\"sorting\"] == \"ascending\":\n",
        "        # we sort training data to speed up training and get better results.\n",
        "        train_data = train_data.filtered_sorted(sort_key=\"duration\")\n",
        "        # when sorting do not shuffle in dataloader ! otherwise is pointless\n",
        "        hparams[\"train_dataloader_opts\"][\"shuffle\"] = False\n",
        "\n",
        "    elif hparams[\"sorting\"] == \"descending\":\n",
        "        train_data = train_data.filtered_sorted(\n",
        "            sort_key=\"duration\", reverse=True\n",
        "        )\n",
        "        # when sorting do not shuffle in dataloader ! otherwise is pointless\n",
        "        hparams[\"train_dataloader_opts\"][\"shuffle\"] = False\n",
        "\n",
        "    elif hparams[\"sorting\"] == \"random\":\n",
        "        pass\n",
        "\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            \"sorting must be random, ascending or descending\"\n",
        "        )\n",
        "\n",
        "    valid_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n",
        "        csv_path=hparams[\"valid_annotation\"],\n",
        "        replacements={\"data_root\": data_folder},\n",
        "    )\n",
        "    valid_data = valid_data.filtered_sorted(sort_key=\"duration\")\n",
        "\n",
        "    test_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n",
        "        csv_path=hparams[\"test_annotation\"],\n",
        "        replacements={\"data_root\": data_folder},\n",
        "    )\n",
        "    test_data = test_data.filtered_sorted(sort_key=\"duration\")\n",
        "\n",
        "    datasets = [train_data, valid_data, test_data]\n",
        "    label_encoder = sb.dataio.encoder.CTCTextEncoder()\n",
        "\n",
        "    # 2. Define audio pipeline:\n",
        "    @sb.utils.data_pipeline.takes(\"wav\")\n",
        "    @sb.utils.data_pipeline.provides(\"sig\")\n",
        "    def audio_pipeline(wav):\n",
        "        # sig = sb.dataio.dataio.read_audio(wav)\n",
        "        # # sample rate change to 16000, e,g, using librosa\n",
        "        # sig = torch.Tensor(librosa.core.load(wav, hparams[\"sample_rate\"])[0])\n",
        "        # Use wav2vec processor to do normalization\n",
        "        sig = hparams[\"wav2vec2\"].feature_extractor(\n",
        "            librosa.core.load(wav, sr=hparams[\"sample_rate\"])[0],\n",
        "            sampling_rate=hparams[\"sample_rate\"],\n",
        "        ).input_values[0]\n",
        "        sig = torch.Tensor(sig)\n",
        "        return sig\n",
        "\n",
        "    sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline)\n",
        "\n",
        "    # 3. Define text pipeline:\n",
        "    @sb.utils.data_pipeline.takes(\"perceived_train_target\")\n",
        "    @sb.utils.data_pipeline.provides(\n",
        "        \"phn_list_target\",\n",
        "        \"phn_encoded_list_target\",\n",
        "        \"phn_encoded_target\",\n",
        "    )\n",
        "    def text_pipeline_train(phn):\n",
        "        phn_list = phn.strip().split()\n",
        "        yield phn_list\n",
        "        phn_encoded_list = label_encoder.encode_sequence(phn_list)\n",
        "        yield phn_encoded_list\n",
        "        phn_encoded = torch.LongTensor(phn_encoded_list)\n",
        "        yield phn_encoded\n",
        "\n",
        "    @sb.utils.data_pipeline.takes(\"perceived_train_target\", \"canonical_aligned\", \"perceived_aligned\")\n",
        "    @sb.utils.data_pipeline.provides(\n",
        "        \"phn_list_target\",\n",
        "        \"phn_encoded_list_target\",\n",
        "        \"phn_encoded_target\",\n",
        "        \"phn_list_canonical\",\n",
        "        \"phn_encoded_list_canonical\",\n",
        "        \"phn_encoded_canonical\",\n",
        "        \"phn_list_perceived\",\n",
        "        \"phn_encoded_list_perceived\",\n",
        "        \"phn_encoded_perceived\",\n",
        "    )\n",
        "    def text_pipeline_test(target, canonical, perceived):\n",
        "        phn_list_target = target.strip().split()\n",
        "        yield phn_list_target\n",
        "        phn_encoded_list_target = label_encoder.encode_sequence(phn_list_target)\n",
        "        yield phn_encoded_list_target\n",
        "        phn_encoded_target = torch.LongTensor(phn_encoded_list_target)\n",
        "        yield phn_encoded_target\n",
        "        phn_list_canonical = canonical.strip().split()\n",
        "        yield phn_list_canonical\n",
        "        phn_encoded_list_canonical = label_encoder.encode_sequence(phn_list_canonical)\n",
        "        yield phn_encoded_list_canonical\n",
        "        phn_encoded_canonical = torch.LongTensor(phn_encoded_list_canonical)\n",
        "        yield phn_encoded_canonical\n",
        "        phn_list_perceived = perceived.strip().split()\n",
        "        yield phn_list_perceived\n",
        "        phn_encoded_list_perceived = label_encoder.encode_sequence(phn_list_perceived)\n",
        "        yield phn_encoded_list_perceived\n",
        "        phn_encoded_perceived = torch.LongTensor(phn_encoded_list_perceived)\n",
        "        yield phn_encoded_perceived\n",
        "\n",
        "    sb.dataio.dataset.add_dynamic_item([train_data], text_pipeline_train)\n",
        "    sb.dataio.dataset.add_dynamic_item([valid_data, test_data], text_pipeline_test)\n",
        "\n",
        "    # 3. Fit encoder:\n",
        "    # Load or compute the label encoder\n",
        "    lab_enc_file = os.path.join(hparams[\"save_folder\"], \"label_encoder.txt\")\n",
        "    special_labels = {\n",
        "        \"blank_label\": hparams[\"blank_index\"],\n",
        "    }\n",
        "    label_encoder.load_or_create(\n",
        "        path=lab_enc_file,\n",
        "        from_didatasets=[train_data],\n",
        "        output_key=\"phn_list_target\",\n",
        "        special_labels=special_labels,\n",
        "        sequence_input=True,\n",
        "    )\n",
        "\n",
        "    # 4. Set output:\n",
        "    sb.dataio.dataset.set_output_keys(\n",
        "        [train_data],\n",
        "        [\"id\", \"sig\", \"phn_encoded_target\"],\n",
        "    )\n",
        "    sb.dataio.dataset.set_output_keys(\n",
        "        [valid_data, test_data],\n",
        "        [\"id\", \"sig\", \"phn_encoded_target\", \"phn_encoded_canonical\", \"phn_encoded_perceived\"],\n",
        "    )\n",
        "\n",
        "    return train_data, valid_data, test_data, label_encoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating data loaders"
      ],
      "metadata": {
        "collapsed": false,
        "id": "TuJfRDquo8TD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "yVsbqzMyJBRL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74211e94-6304-4a12-ef75-51cbde682569"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/hubert-base-ls960 were not used when initializing HubertModel: ['encoder.pos_conv_embed.conv.weight_g', 'encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing HubertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing HubertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of HubertModel were not initialized from the model checkpoint at facebook/hubert-base-ls960 and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.lobes.models.huggingface_wav2vec - speechbrain.lobes.models.huggingface_wav2vec - wav2vec 2.0 feature extractor is frozen.\n",
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/hubert-base_ctc/\n",
            "speechbrain.dataio.encoder - Load called, but CTCTextEncoder is not empty. Loaded data will overwrite everything. This is normal if there is e.g. an unk label defined at init.\n"
          ]
        }
      ],
      "source": [
        "hparams_file = '/content/drive/MyDrive/CS5647_Project/hubert/hparams/train.yaml'\n",
        "\n",
        "# Load hyperparameters file with command-line overrides\n",
        "with open(hparams_file) as fin:\n",
        "    hparams = load_hyperpyyaml(fin)\n",
        "\n",
        "\n",
        "# Create experiment directory\n",
        "sb.create_experiment_directory(\n",
        "    experiment_directory=hparams[\"output_folder\"],\n",
        "    hyperparams_to_save=hparams_file,\n",
        ")\n",
        "\n",
        "# Dataset IO prep: creating Dataset objects and proper encodings for phones\n",
        "train_data, valid_data, test_data, label_encoder = dataio_prep(hparams)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initializing the ASR Trainer"
      ],
      "metadata": {
        "collapsed": false,
        "id": "73fmBBv_o8TD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "\n",
        "# os.environ[\"NUMEXPR_MAX_THREADS\"] = \"12\""
      ],
      "metadata": {
        "id": "-b_FGnT7CaUe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "QQHyc36_74th",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a6dd05d-4960-43d2-da28-aaa08d33436b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.core - Info: auto_mix_prec arg from hparam file is used\n",
            "speechbrain.core - 90.6M trainable parameters in ASR\n"
          ]
        }
      ],
      "source": [
        "# Trainer initialization\n",
        "asr_brain = ASR(\n",
        "    modules=hparams[\"modules\"],\n",
        "    hparams=hparams,\n",
        "    checkpointer=hparams[\"checkpointer\"],\n",
        "    run_opts = {\"device\": \"cuda\"}\n",
        ")\n",
        "asr_brain.label_encoder = label_encoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the ASR Model"
      ],
      "metadata": {
        "collapsed": false,
        "id": "c5qOq49do8TE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\n",
            "speechbrain.utils.epoch_loop - Going into epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/100 [00:03<?, ?it/s]/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "100%|██████████| 100/100 [07:16<00:00,  4.36s/it, train_loss=5.55]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/50 [00:13<?, ?it/s]/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/dataio/encoder.py:722: UserWarning: CTCTextEncoder.expect_len was never called: assuming category count of 42 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
            "  warnings.warn(\n",
            "100%|██████████| 50/50 [03:45<00:00,  4.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 1, lr_model: 3.00e-04, lr_wav2vec2: 1.00e-05 - train loss: 5.55 - valid loss: 3.64, valid ctc_loss: 3.64, valid PER: 1.00e+02, valid mpd_f1: 2.00e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-33-31+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:15<00:00,  6.58it/s, train_loss=3.33]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 2, lr_model: 3.00e-04, lr_wav2vec2: 1.00e-05 - train loss: 3.33 - valid loss: 3.08, valid ctc_loss: 3.08, valid PER: 96.58, valid mpd_f1: 2.00e-01\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-33-55+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-33-31+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:14<00:00,  6.83it/s, train_loss=2.64]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 3, lr_model: 3.00e-04, lr_wav2vec2: 1.00e-05 - train loss: 2.64 - valid loss: 1.83, valid ctc_loss: 1.83, valid PER: 81.26, valid mpd_f1: 2.16e-01\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-34-18+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-33-55+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.24it/s, train_loss=1.69]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 4, lr_model: 3.00e-04, lr_wav2vec2: 1.00e-05 - train loss: 1.69 - valid loss: 1.10, valid ctc_loss: 1.10, valid PER: 45.60, valid mpd_f1: 3.18e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-34-41+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-34-18+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.37it/s, train_loss=1.33]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 5, lr_model: 3.00e-04, lr_wav2vec2: 1.00e-05 - train loss: 1.33 - valid loss: 9.05e-01, valid ctc_loss: 9.05e-01, valid PER: 35.35, valid mpd_f1: 3.61e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-35-07+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-34-41+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.35it/s, train_loss=1.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 6, lr_model: 3.00e-04, lr_wav2vec2: 1.00e-05 - train loss: 1.20 - valid loss: 8.36e-01, valid ctc_loss: 8.36e-01, valid PER: 34.00, valid mpd_f1: 3.64e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-35-29+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-35-07+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.39it/s, train_loss=1.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 7, lr_model: 3.00e-04, lr_wav2vec2: 1.00e-05 - train loss: 1.10 - valid loss: 7.70e-01, valid ctc_loss: 7.70e-01, valid PER: 28.44, valid mpd_f1: 3.87e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-35-51+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-35-29+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.35it/s, train_loss=1.05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 8, lr_model: 3.00e-04, lr_wav2vec2: 1.00e-05 - train loss: 1.05 - valid loss: 7.45e-01, valid ctc_loss: 7.45e-01, valid PER: 26.82, valid mpd_f1: 3.96e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-36-13+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-35-51+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.36it/s, train_loss=0.967]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 9, lr_model: 3.00e-04, lr_wav2vec2: 1.00e-05 - train loss: 9.67e-01 - valid loss: 7.01e-01, valid ctc_loss: 7.01e-01, valid PER: 23.72, valid mpd_f1: 4.27e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-36-35+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-36-13+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.50it/s, train_loss=0.96]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 10, lr_model: 3.00e-04, lr_wav2vec2: 1.00e-05 - train loss: 9.60e-01 - valid loss: 6.86e-01, valid ctc_loss: 6.86e-01, valid PER: 23.03, valid mpd_f1: 4.24e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-36-57+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.45it/s, train_loss=0.877]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 11, lr_model: 3.00e-04, lr_wav2vec2: 1.00e-05 - train loss: 8.77e-01 - valid loss: 6.64e-01, valid ctc_loss: 6.64e-01, valid PER: 21.32, valid mpd_f1: 4.24e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-37-19+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-36-57+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.40it/s, train_loss=0.86]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 12, lr_model: 3.00e-04, lr_wav2vec2: 1.00e-05 - train loss: 8.60e-01 - valid loss: 6.35e-01, valid ctc_loss: 6.35e-01, valid PER: 19.76, valid mpd_f1: 4.36e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-37-44+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-37-19+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-36-35+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.31it/s, train_loss=0.825]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  8.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 13, lr_model: 3.00e-04, lr_wav2vec2: 1.00e-05 - train loss: 8.25e-01 - valid loss: 6.18e-01, valid ctc_loss: 6.18e-01, valid PER: 19.12, valid mpd_f1: 4.53e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-38-09+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-37-44+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.44it/s, train_loss=0.81]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 14, lr_model: 3.00e-04, lr_wav2vec2: 1.00e-05 - train loss: 8.10e-01 - valid loss: 6.14e-01, valid ctc_loss: 6.14e-01, valid PER: 18.62, valid mpd_f1: 4.52e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-38-32+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.46it/s, train_loss=0.799]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 15, lr_model: 3.00e-04, lr_wav2vec2: 1.00e-05 - train loss: 7.99e-01 - valid loss: 6.03e-01, valid ctc_loss: 6.03e-01, valid PER: 18.46, valid mpd_f1: 4.48e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-38-54+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-38-32+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.30it/s, train_loss=0.763]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  8.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 16, lr_model: 3.00e-04, lr_wav2vec2: 1.00e-05 - train loss: 7.63e-01 - valid loss: 5.96e-01, valid ctc_loss: 5.96e-01, valid PER: 18.05, valid mpd_f1: 4.42e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-39-19+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-38-54+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.33it/s, train_loss=0.762]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 17, lr_model: 3.00e-04, lr_wav2vec2: 1.00e-05 - train loss: 7.62e-01 - valid loss: 5.78e-01, valid ctc_loss: 5.78e-01, valid PER: 17.35, valid mpd_f1: 4.57e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-39-42+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-39-19+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-38-09+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.42it/s, train_loss=0.752]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 18, lr_model: 3.00e-04, lr_wav2vec2: 1.00e-05 - train loss: 7.52e-01 - valid loss: 5.75e-01, valid ctc_loss: 5.75e-01, valid PER: 17.28, valid mpd_f1: 4.69e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-40-04+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-39-42+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.26it/s, train_loss=0.707]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  8.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 19, lr_model: 3.00e-04, lr_wav2vec2: 1.00e-05 - train loss: 7.07e-01 - valid loss: 5.76e-01, valid ctc_loss: 5.76e-01, valid PER: 17.64, valid mpd_f1: 4.53e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-40-27+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.24it/s, train_loss=0.689]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 20, lr_model: 3.00e-04, lr_wav2vec2: 1.00e-05 - train loss: 6.89e-01 - valid loss: 5.70e-01, valid ctc_loss: 5.70e-01, valid PER: 17.15, valid mpd_f1: 4.58e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-40-50+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-40-27+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.47it/s, train_loss=0.672]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 21, lr_model: 3.00e-04, lr_wav2vec2: 1.00e-05 - train loss: 6.72e-01 - valid loss: 5.61e-01, valid ctc_loss: 5.61e-01, valid PER: 17.14, valid mpd_f1: 4.70e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-41-15+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-40-50+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-40-04+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.35it/s, train_loss=0.695]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  8.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 22, lr_model: 3.00e-04, lr_wav2vec2: 1.00e-05 - train loss: 6.95e-01 - valid loss: 5.56e-01, valid ctc_loss: 5.56e-01, valid PER: 17.11, valid mpd_f1: 4.47e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-41-38+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.42it/s, train_loss=0.665]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.nnet.schedulers - Changing lr from 0.0003 to 0.00022\n",
            "speechbrain.nnet.schedulers - Changing lr from 1e-05 to 7.5e-06\n",
            "speechbrain.utils.train_logger - epoch: 23, lr_model: 3.00e-04, lr_wav2vec2: 1.00e-05 - train loss: 6.65e-01 - valid loss: 5.63e-01, valid ctc_loss: 5.63e-01, valid PER: 17.19, valid mpd_f1: 4.50e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-42-00+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.35it/s, train_loss=0.636]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 24, lr_model: 2.25e-04, lr_wav2vec2: 7.50e-06 - train loss: 6.36e-01 - valid loss: 5.57e-01, valid ctc_loss: 5.57e-01, valid PER: 17.18, valid mpd_f1: 4.53e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-42-22+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-42-00+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.59it/s, train_loss=0.656]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 25, lr_model: 2.25e-04, lr_wav2vec2: 7.50e-06 - train loss: 6.56e-01 - valid loss: 5.56e-01, valid ctc_loss: 5.56e-01, valid PER: 16.68, valid mpd_f1: 4.44e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-42-44+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-41-38+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-42-22+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:14<00:00,  6.96it/s, train_loss=0.638]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 26, lr_model: 2.25e-04, lr_wav2vec2: 7.50e-06 - train loss: 6.38e-01 - valid loss: 5.52e-01, valid ctc_loss: 5.52e-01, valid PER: 16.79, valid mpd_f1: 4.37e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-43-08+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.28it/s, train_loss=0.599]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 27, lr_model: 2.25e-04, lr_wav2vec2: 7.50e-06 - train loss: 5.99e-01 - valid loss: 5.49e-01, valid ctc_loss: 5.49e-01, valid PER: 16.77, valid mpd_f1: 4.43e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-43-30+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-43-08+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.47it/s, train_loss=0.606]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.nnet.schedulers - Changing lr from 0.00022 to 0.00017\n",
            "speechbrain.nnet.schedulers - Changing lr from 7.5e-06 to 5.6e-06\n",
            "speechbrain.utils.train_logger - epoch: 28, lr_model: 2.25e-04, lr_wav2vec2: 7.50e-06 - train loss: 6.06e-01 - valid loss: 5.52e-01, valid ctc_loss: 5.52e-01, valid PER: 16.97, valid mpd_f1: 4.64e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-43-56+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-43-30+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.29it/s, train_loss=0.606]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  8.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 29, lr_model: 1.69e-04, lr_wav2vec2: 5.63e-06 - train loss: 6.06e-01 - valid loss: 5.46e-01, valid ctc_loss: 5.46e-01, valid PER: 16.87, valid mpd_f1: 4.45e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-44-22+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-43-56+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.28it/s, train_loss=0.599]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  8.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 30, lr_model: 1.69e-04, lr_wav2vec2: 5.63e-06 - train loss: 5.99e-01 - valid loss: 5.44e-01, valid ctc_loss: 5.44e-01, valid PER: 16.33, valid mpd_f1: 4.38e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-44-45+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-44-22+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-42-44+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.39it/s, train_loss=0.594]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  8.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 31, lr_model: 1.69e-04, lr_wav2vec2: 5.63e-06 - train loss: 5.94e-01 - valid loss: 5.42e-01, valid ctc_loss: 5.42e-01, valid PER: 16.33, valid mpd_f1: 4.43e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-45-08+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-44-45+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.28it/s, train_loss=0.574]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 32, lr_model: 1.69e-04, lr_wav2vec2: 5.63e-06 - train loss: 5.74e-01 - valid loss: 5.49e-01, valid ctc_loss: 5.49e-01, valid PER: 16.14, valid mpd_f1: 4.29e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-45-30+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-45-08+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.32it/s, train_loss=0.548]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  8.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.nnet.schedulers - Changing lr from 0.00017 to 0.00013\n",
            "speechbrain.nnet.schedulers - Changing lr from 5.6e-06 to 4.2e-06\n",
            "speechbrain.utils.train_logger - epoch: 33, lr_model: 1.69e-04, lr_wav2vec2: 5.63e-06 - train loss: 5.48e-01 - valid loss: 5.49e-01, valid ctc_loss: 5.49e-01, valid PER: 16.39, valid mpd_f1: 4.39e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-45-54+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.20it/s, train_loss=0.553]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  7.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 34, lr_model: 1.27e-04, lr_wav2vec2: 4.22e-06 - train loss: 5.53e-01 - valid loss: 5.48e-01, valid ctc_loss: 5.48e-01, valid PER: 16.30, valid mpd_f1: 4.41e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-46-17+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-45-54+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:14<00:00,  7.05it/s, train_loss=0.551]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  8.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.nnet.schedulers - Changing lr from 0.00013 to 9.5e-05\n",
            "speechbrain.nnet.schedulers - Changing lr from 4.2e-06 to 3.2e-06\n",
            "speechbrain.utils.train_logger - epoch: 35, lr_model: 1.27e-04, lr_wav2vec2: 4.22e-06 - train loss: 5.51e-01 - valid loss: 5.52e-01, valid ctc_loss: 5.52e-01, valid PER: 16.30, valid mpd_f1: 4.38e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-46-40+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-46-17+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.22it/s, train_loss=0.582]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  7.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 36, lr_model: 9.49e-05, lr_wav2vec2: 3.16e-06 - train loss: 5.82e-01 - valid loss: 5.44e-01, valid ctc_loss: 5.44e-01, valid PER: 16.07, valid mpd_f1: 4.33e-01\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-47-05+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-45-30+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-46-40+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.36it/s, train_loss=0.521]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  8.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 37, lr_model: 9.49e-05, lr_wav2vec2: 3.16e-06 - train loss: 5.21e-01 - valid loss: 5.47e-01, valid ctc_loss: 5.47e-01, valid PER: 16.05, valid mpd_f1: 4.41e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-47-28+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-47-05+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.28it/s, train_loss=0.554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 38, lr_model: 9.49e-05, lr_wav2vec2: 3.16e-06 - train loss: 5.54e-01 - valid loss: 5.45e-01, valid ctc_loss: 5.45e-01, valid PER: 16.16, valid mpd_f1: 4.33e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-47-53+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.39it/s, train_loss=0.52]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.nnet.schedulers - Changing lr from 9.5e-05 to 7.1e-05\n",
            "speechbrain.nnet.schedulers - Changing lr from 3.2e-06 to 2.4e-06\n",
            "speechbrain.utils.train_logger - epoch: 39, lr_model: 9.49e-05, lr_wav2vec2: 3.16e-06 - train loss: 5.20e-01 - valid loss: 5.49e-01, valid ctc_loss: 5.49e-01, valid PER: 16.23, valid mpd_f1: 4.25e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-48-16+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-47-53+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.48it/s, train_loss=0.557]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 40, lr_model: 7.12e-05, lr_wav2vec2: 2.37e-06 - train loss: 5.57e-01 - valid loss: 5.47e-01, valid ctc_loss: 5.47e-01, valid PER: 15.97, valid mpd_f1: 4.38e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-48-38+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-48-16+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-47-28+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.37it/s, train_loss=0.544]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 41, lr_model: 7.12e-05, lr_wav2vec2: 2.37e-06 - train loss: 5.44e-01 - valid loss: 5.44e-01, valid ctc_loss: 5.44e-01, valid PER: 16.15, valid mpd_f1: 4.34e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-49-01+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.51it/s, train_loss=0.528]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 42, lr_model: 7.12e-05, lr_wav2vec2: 2.37e-06 - train loss: 5.28e-01 - valid loss: 5.45e-01, valid ctc_loss: 5.45e-01, valid PER: 15.96, valid mpd_f1: 4.36e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-49-25+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-48-38+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-49-01+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.25it/s, train_loss=0.53]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.nnet.schedulers - Changing lr from 7.1e-05 to 5.3e-05\n",
            "speechbrain.nnet.schedulers - Changing lr from 2.4e-06 to 1.8e-06\n",
            "speechbrain.utils.train_logger - epoch: 43, lr_model: 7.12e-05, lr_wav2vec2: 2.37e-06 - train loss: 5.30e-01 - valid loss: 5.45e-01, valid ctc_loss: 5.45e-01, valid PER: 15.72, valid mpd_f1: 4.40e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-49-52+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-49-25+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.16it/s, train_loss=0.532]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 44, lr_model: 5.34e-05, lr_wav2vec2: 1.78e-06 - train loss: 5.32e-01 - valid loss: 5.43e-01, valid ctc_loss: 5.43e-01, valid PER: 15.77, valid mpd_f1: 4.43e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-50-15+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.30it/s, train_loss=0.509]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 45, lr_model: 5.34e-05, lr_wav2vec2: 1.78e-06 - train loss: 5.09e-01 - valid loss: 5.41e-01, valid ctc_loss: 5.41e-01, valid PER: 15.66, valid mpd_f1: 4.52e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-50-38+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-49-52+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-50-15+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.21it/s, train_loss=0.508]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  8.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 46, lr_model: 5.34e-05, lr_wav2vec2: 1.78e-06 - train loss: 5.08e-01 - valid loss: 5.43e-01, valid ctc_loss: 5.43e-01, valid PER: 15.75, valid mpd_f1: 4.47e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-51-04+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.32it/s, train_loss=0.552]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  8.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.nnet.schedulers - Changing lr from 5.3e-05 to 4e-05\n",
            "speechbrain.nnet.schedulers - Changing lr from 1.8e-06 to 1.3e-06\n",
            "speechbrain.utils.train_logger - epoch: 47, lr_model: 5.34e-05, lr_wav2vec2: 1.78e-06 - train loss: 5.52e-01 - valid loss: 5.43e-01, valid ctc_loss: 5.43e-01, valid PER: 15.70, valid mpd_f1: 4.43e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-51-27+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-51-04+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.18it/s, train_loss=0.495]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  8.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 48, lr_model: 4.00e-05, lr_wav2vec2: 1.33e-06 - train loss: 4.95e-01 - valid loss: 5.43e-01, valid ctc_loss: 5.43e-01, valid PER: 15.71, valid mpd_f1: 4.47e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-51-51+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-51-27+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.26it/s, train_loss=0.507]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 49, lr_model: 4.00e-05, lr_wav2vec2: 1.33e-06 - train loss: 5.07e-01 - valid loss: 5.39e-01, valid ctc_loss: 5.39e-01, valid PER: 15.61, valid mpd_f1: 4.57e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-52-15+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-51-51+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-50-38+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.35it/s, train_loss=0.513]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  8.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.nnet.schedulers - Changing lr from 4e-05 to 3e-05\n",
            "speechbrain.nnet.schedulers - Changing lr from 1.3e-06 to 1e-06\n",
            "speechbrain.utils.train_logger - epoch: 50, lr_model: 4.00e-05, lr_wav2vec2: 1.33e-06 - train loss: 5.13e-01 - valid loss: 5.40e-01, valid ctc_loss: 5.40e-01, valid PER: 15.75, valid mpd_f1: 4.47e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/hubert-base_ctc/save/CKPT+2023-11-23+10-52-41+00\n"
          ]
        }
      ],
      "source": [
        "# Training/validation loop\n",
        "asr_brain.fit(\n",
        "    asr_brain.hparams.epoch_counter,\n",
        "    train_data,\n",
        "    valid_data,\n",
        "    train_loader_kwargs=hparams[\"train_dataloader_opts\"],\n",
        "    valid_loader_kwargs=hparams[\"valid_dataloader_opts\"],\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kUlur1go8TE",
        "outputId": "40886bc1-3f98-44fb-f301-f6222ced0693"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the ASR Model"
      ],
      "metadata": {
        "collapsed": false,
        "id": "AB4gvHRYo8TE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "asr_brain.evaluate(\n",
        "    test_data,\n",
        "    min_key=\"PER\",\n",
        "    test_loader_kwargs=hparams[\"test_dataloader_opts\"],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4tSMlfL7lCb",
        "outputId": "7a2edcae-71e9-40fb-b067-c77b91258595"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/hubert-base_ctc/save/CKPT+2023-11-23+10-52-15+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numexpr.utils - NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [03:43<00:00,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - Epoch loaded: 49 - test loss: 6.84e-01, test PER: 17.17, test mpd_f1: 4.02e-01\n",
            "CTC and PER stats written to file results/hubert-base_ctc//wer.txt\n",
            "MPD results and stats written to file results/hubert-base_ctc//mpd.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6837410604705413"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making inference on a single audio file"
      ],
      "metadata": {
        "id": "Njo4uu4Zl8cJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_audio_path = \"/content/drive/MyDrive/CS5647_Project/dataset/TNI/wav/arctic_a0100.wav\"\n",
        "canonical_phonemes = \"sil y uw m ah s t s l iy p sil hh iy er jh d sil sil\" # actual sentence is 'You must sleep he urged'\n",
        "predicted_phonemes, score, stats = asr_brain.evaluate_test_audio(test_audio_path, canonical_phonemes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edd0Y_StHhIw",
        "outputId": "1ef1eb85-ac63-44fc-deb4-bd9ba2cb1b81"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using librosa to load the audio\n",
            "numexpr.utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "numexpr.utils - NumExpr defaulting to 8 threads.\n",
            "Loading the best model & setting to eval mode\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/hubert-base_ctc/save/CKPT+2023-11-23+10-52-15+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-d18af24fba10>:180: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  sig = torch.Tensor(sig)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Making predictions from the best model\n",
            "Got the predictions\n",
            "Converting canonical to appropriate format for getting error\n",
            "Getting the error stats\n",
            "Calculated the score to be: 63.1578947368421\n",
            "Now capturing the stats sysout in a variable\n",
            "Extracting stats from stdout\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63.1578947368421"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0CVKoMRo8TE",
        "outputId": "03c86262-7ea3-41db-e0e5-d5859207793f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_phonemes"
      ],
      "metadata": {
        "id": "nh60DUuPViI5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b35d409-2f2e-4b4b-d1b4-211c341c1a36"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sil y uw m ah s l iy hh iy er ch t sil']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'deletions': {'canonical': [(6, 't'),\n",
              "   (7, 's'),\n",
              "   (10, 'p'),\n",
              "   (11, 'sil'),\n",
              "   (18, 'sil')],\n",
              "  'predicted': [(6, '<eps>'),\n",
              "   (7, '<eps>'),\n",
              "   (10, '<eps>'),\n",
              "   (11, '<eps>'),\n",
              "   (18, '<eps>')]},\n",
              " 'insertions': {'canonical': [], 'predicted': []},\n",
              " 'substitutions': {'canonical': [(15, 'jh'), (16, 'd')],\n",
              "  'predicted': [(15, 'ch'), (16, 't')]},\n",
              " 'canonical': ['sil',\n",
              "  'y',\n",
              "  'uw',\n",
              "  'm',\n",
              "  'ah',\n",
              "  's',\n",
              "  't',\n",
              "  's',\n",
              "  'l',\n",
              "  'iy',\n",
              "  'p',\n",
              "  'sil',\n",
              "  'hh',\n",
              "  'iy',\n",
              "  'er',\n",
              "  'jh',\n",
              "  'd',\n",
              "  'sil',\n",
              "  'sil'],\n",
              " 'predicted': ['sil',\n",
              "  'y',\n",
              "  'uw',\n",
              "  'm',\n",
              "  'ah',\n",
              "  's',\n",
              "  '<eps>',\n",
              "  '<eps>',\n",
              "  'l',\n",
              "  'iy',\n",
              "  '<eps>',\n",
              "  '<eps>',\n",
              "  'hh',\n",
              "  'iy',\n",
              "  'er',\n",
              "  'ch',\n",
              "  't',\n",
              "  'sil',\n",
              "  '<eps>']}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xM8JzUMxo8TE",
        "outputId": "6864e9dd-7ef9-4a11-8b52-c538eb55c902"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}